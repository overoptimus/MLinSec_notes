{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([Dense(32, input_shape=(784,)), Activation('relu'), Dense(10), Activation('softmax'), ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7fb16bc2b780>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'float32'"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "model.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data: (1000, 100) \n",
      "labels: (1000, 1)\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 1s 838us/step - loss: 0.7011 - accuracy: 0.4747\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 0s 862us/step - loss: 0.6917 - accuracy: 0.5234\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 0s 881us/step - loss: 0.6909 - accuracy: 0.5108\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 0s 697us/step - loss: 0.6870 - accuracy: 0.5489\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 0s 803us/step - loss: 0.6783 - accuracy: 0.5908\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 0s 993us/step - loss: 0.6855 - accuracy: 0.5352\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 0s 883us/step - loss: 0.6784 - accuracy: 0.5748\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 0s 882us/step - loss: 0.6754 - accuracy: 0.5898\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 0s 936us/step - loss: 0.6732 - accuracy: 0.5836\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 0s 849us/step - loss: 0.6697 - accuracy: 0.5942\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 0s 754us/step - loss: 0.6691 - accuracy: 0.5945\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 0s 712us/step - loss: 0.6680 - accuracy: 0.6023\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 0s 696us/step - loss: 0.6633 - accuracy: 0.6241\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 0s 843us/step - loss: 0.6571 - accuracy: 0.6255\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 0s 816us/step - loss: 0.6630 - accuracy: 0.6070\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 0s 792us/step - loss: 0.6480 - accuracy: 0.6504\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 0s 735us/step - loss: 0.6460 - accuracy: 0.6437\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 0s 816us/step - loss: 0.6507 - accuracy: 0.6343\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 0s 898us/step - loss: 0.6440 - accuracy: 0.6696\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 0s 760us/step - loss: 0.6438 - accuracy: 0.6679\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 0s 738us/step - loss: 0.6413 - accuracy: 0.6549\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 0s 734us/step - loss: 0.6257 - accuracy: 0.6786\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 0s 839us/step - loss: 0.6361 - accuracy: 0.6688\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.6215 - accuracy: 0.6606\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 0s 944us/step - loss: 0.6374 - accuracy: 0.6769\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 0s 716us/step - loss: 0.6136 - accuracy: 0.7079\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 0s 809us/step - loss: 0.6266 - accuracy: 0.6778\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 0s 808us/step - loss: 0.6126 - accuracy: 0.6783\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 0s 789us/step - loss: 0.6131 - accuracy: 0.6997\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 0s 726us/step - loss: 0.6056 - accuracy: 0.7163\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 0s 826us/step - loss: 0.6149 - accuracy: 0.6838\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 0s 834us/step - loss: 0.5946 - accuracy: 0.7084\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 0s 938us/step - loss: 0.5990 - accuracy: 0.7085\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 0s 862us/step - loss: 0.5874 - accuracy: 0.7233\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 0s 921us/step - loss: 0.5984 - accuracy: 0.7003\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 0s 852us/step - loss: 0.5880 - accuracy: 0.7000\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 0s 854us/step - loss: 0.5766 - accuracy: 0.7312\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 0s 967us/step - loss: 0.5843 - accuracy: 0.7183\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 0s 919us/step - loss: 0.5714 - accuracy: 0.7407\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 0s 925us/step - loss: 0.5740 - accuracy: 0.7282\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 0s 807us/step - loss: 0.5629 - accuracy: 0.7238\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 0s 738us/step - loss: 0.5532 - accuracy: 0.7457\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 0s 767us/step - loss: 0.5735 - accuracy: 0.7123\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 0s 764us/step - loss: 0.5638 - accuracy: 0.7337\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 0s 864us/step - loss: 0.5562 - accuracy: 0.7502\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 0s 885us/step - loss: 0.5555 - accuracy: 0.7437\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 0s 877us/step - loss: 0.5396 - accuracy: 0.7597\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 0s 869us/step - loss: 0.5576 - accuracy: 0.7222\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 0s 994us/step - loss: 0.5562 - accuracy: 0.7290\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 0s 869us/step - loss: 0.5428 - accuracy: 0.7390\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb16c813128>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# 对于具有2个类的单输入模型（二进制分类）\n",
    "model = Sequential()\n",
    "model.add(Dense(20, activation='relu', input_dim=100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 生成虚拟数据\n",
    "import numpy as np\n",
    "data = np.random.random((1000,100))\n",
    "labels = np.random.randint(2, size=(1000,1))\n",
    "print('data:', data.shape, '\\nlabels:', labels.shape)\n",
    "\n",
    "# 训练数据，以32个样本为一个batch进行迭代\n",
    "model.fit(data, labels, epochs=50, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.32855707 0.70136807 0.95634031 ... 0.09654034 0.25590947 0.90036142]\n",
      " [0.76369721 0.30691001 0.77117923 ... 0.6919517  0.28911124 0.23715154]\n",
      " [0.27823695 0.09597128 0.73888068 ... 0.81372184 0.040698   0.58076478]\n",
      " ...\n",
      " [0.72401469 0.97449916 0.85634079 ... 0.70768842 0.95720181 0.01171801]\n",
      " [0.66677618 0.85052962 0.90511609 ... 0.85501317 0.64278016 0.51435849]\n",
      " [0.18039436 0.52750604 0.75577823 ... 0.78572408 0.9655385  0.51937494]]\n",
      "data: (1000, 100) \n",
      "labels: (1000, 1)\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 2,230\n",
      "Trainable params: 2,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/550\n",
      "34/34 [==============================] - 0s 689us/step - loss: 2.4211 - accuracy: 0.0976\n",
      "Epoch 2/550\n",
      "34/34 [==============================] - 0s 710us/step - loss: 2.3289 - accuracy: 0.1023\n",
      "Epoch 3/550\n",
      "34/34 [==============================] - 0s 736us/step - loss: 2.3172 - accuracy: 0.1144\n",
      "Epoch 4/550\n",
      "34/34 [==============================] - 0s 788us/step - loss: 2.3013 - accuracy: 0.1143\n",
      "Epoch 5/550\n",
      "34/34 [==============================] - 0s 872us/step - loss: 2.2974 - accuracy: 0.1175\n",
      "Epoch 6/550\n",
      "34/34 [==============================] - 0s 721us/step - loss: 2.2920 - accuracy: 0.1247\n",
      "Epoch 7/550\n",
      "34/34 [==============================] - 0s 659us/step - loss: 2.2877 - accuracy: 0.1267\n",
      "Epoch 8/550\n",
      "34/34 [==============================] - 0s 715us/step - loss: 2.2740 - accuracy: 0.1530\n",
      "Epoch 9/550\n",
      "34/34 [==============================] - 0s 769us/step - loss: 2.2731 - accuracy: 0.1146\n",
      "Epoch 10/550\n",
      "34/34 [==============================] - 0s 987us/step - loss: 2.2710 - accuracy: 0.1517\n",
      "Epoch 11/550\n",
      "34/34 [==============================] - 0s 983us/step - loss: 2.2547 - accuracy: 0.1744\n",
      "Epoch 12/550\n",
      "34/34 [==============================] - 0s 834us/step - loss: 2.2638 - accuracy: 0.1597\n",
      "Epoch 13/550\n",
      "34/34 [==============================] - 0s 971us/step - loss: 2.2363 - accuracy: 0.1783\n",
      "Epoch 14/550\n",
      "34/34 [==============================] - 0s 860us/step - loss: 2.2279 - accuracy: 0.2013\n",
      "Epoch 15/550\n",
      "34/34 [==============================] - 0s 895us/step - loss: 2.2418 - accuracy: 0.1739\n",
      "Epoch 16/550\n",
      "34/34 [==============================] - 0s 869us/step - loss: 2.2313 - accuracy: 0.1770\n",
      "Epoch 17/550\n",
      "34/34 [==============================] - 0s 956us/step - loss: 2.2187 - accuracy: 0.1742\n",
      "Epoch 18/550\n",
      "34/34 [==============================] - 0s 859us/step - loss: 2.2106 - accuracy: 0.2149\n",
      "Epoch 19/550\n",
      "34/34 [==============================] - 0s 812us/step - loss: 2.2220 - accuracy: 0.1749\n",
      "Epoch 20/550\n",
      "34/34 [==============================] - 0s 721us/step - loss: 2.2115 - accuracy: 0.2138\n",
      "Epoch 21/550\n",
      "34/34 [==============================] - 0s 741us/step - loss: 2.2018 - accuracy: 0.2029\n",
      "Epoch 22/550\n",
      "34/34 [==============================] - 0s 757us/step - loss: 2.1976 - accuracy: 0.2084\n",
      "Epoch 23/550\n",
      "34/34 [==============================] - 0s 738us/step - loss: 2.1687 - accuracy: 0.2061\n",
      "Epoch 24/550\n",
      "34/34 [==============================] - 0s 792us/step - loss: 2.1825 - accuracy: 0.2235\n",
      "Epoch 25/550\n",
      "34/34 [==============================] - 0s 781us/step - loss: 2.1763 - accuracy: 0.2015\n",
      "Epoch 26/550\n",
      "34/34 [==============================] - 0s 697us/step - loss: 2.1881 - accuracy: 0.1987\n",
      "Epoch 27/550\n",
      "34/34 [==============================] - 0s 733us/step - loss: 2.1463 - accuracy: 0.2507\n",
      "Epoch 28/550\n",
      "34/34 [==============================] - 0s 910us/step - loss: 2.1415 - accuracy: 0.2524\n",
      "Epoch 29/550\n",
      "34/34 [==============================] - 0s 813us/step - loss: 2.1446 - accuracy: 0.2362\n",
      "Epoch 30/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 2.1267 - accuracy: 0.2487\n",
      "Epoch 31/550\n",
      "34/34 [==============================] - 0s 811us/step - loss: 2.1240 - accuracy: 0.2286\n",
      "Epoch 32/550\n",
      "34/34 [==============================] - 0s 889us/step - loss: 2.1063 - accuracy: 0.2656\n",
      "Epoch 33/550\n",
      "34/34 [==============================] - 0s 997us/step - loss: 2.1267 - accuracy: 0.2372\n",
      "Epoch 34/550\n",
      "34/34 [==============================] - 0s 920us/step - loss: 2.0885 - accuracy: 0.2718\n",
      "Epoch 35/550\n",
      "34/34 [==============================] - 0s 730us/step - loss: 2.0703 - accuracy: 0.2826\n",
      "Epoch 36/550\n",
      "34/34 [==============================] - 0s 769us/step - loss: 2.0780 - accuracy: 0.2776\n",
      "Epoch 37/550\n",
      "34/34 [==============================] - 0s 754us/step - loss: 2.0784 - accuracy: 0.2809\n",
      "Epoch 38/550\n",
      "34/34 [==============================] - 0s 714us/step - loss: 2.0763 - accuracy: 0.2682\n",
      "Epoch 39/550\n",
      "34/34 [==============================] - 0s 800us/step - loss: 2.0637 - accuracy: 0.2952\n",
      "Epoch 40/550\n",
      "34/34 [==============================] - 0s 801us/step - loss: 2.0393 - accuracy: 0.2927\n",
      "Epoch 41/550\n",
      "34/34 [==============================] - 0s 970us/step - loss: 2.0689 - accuracy: 0.2875\n",
      "Epoch 42/550\n",
      "34/34 [==============================] - 0s 844us/step - loss: 2.0532 - accuracy: 0.2863\n",
      "Epoch 43/550\n",
      "34/34 [==============================] - 0s 753us/step - loss: 2.0392 - accuracy: 0.3146\n",
      "Epoch 44/550\n",
      "34/34 [==============================] - 0s 781us/step - loss: 2.0424 - accuracy: 0.2815\n",
      "Epoch 45/550\n",
      "34/34 [==============================] - 0s 751us/step - loss: 2.0335 - accuracy: 0.2907\n",
      "Epoch 46/550\n",
      "34/34 [==============================] - 0s 769us/step - loss: 2.0117 - accuracy: 0.2973\n",
      "Epoch 47/550\n",
      "34/34 [==============================] - 0s 742us/step - loss: 2.0100 - accuracy: 0.3153\n",
      "Epoch 48/550\n",
      "34/34 [==============================] - 0s 767us/step - loss: 1.9831 - accuracy: 0.3238\n",
      "Epoch 49/550\n",
      "34/34 [==============================] - 0s 796us/step - loss: 1.9891 - accuracy: 0.3156\n",
      "Epoch 50/550\n",
      "34/34 [==============================] - 0s 745us/step - loss: 1.9945 - accuracy: 0.3158\n",
      "Epoch 51/550\n",
      "34/34 [==============================] - 0s 754us/step - loss: 1.9855 - accuracy: 0.3401\n",
      "Epoch 52/550\n",
      "34/34 [==============================] - 0s 806us/step - loss: 1.9651 - accuracy: 0.3142\n",
      "Epoch 53/550\n",
      "34/34 [==============================] - 0s 736us/step - loss: 1.9811 - accuracy: 0.3266\n",
      "Epoch 54/550\n",
      "34/34 [==============================] - 0s 733us/step - loss: 1.9528 - accuracy: 0.3304\n",
      "Epoch 55/550\n",
      "34/34 [==============================] - 0s 676us/step - loss: 1.9442 - accuracy: 0.3469\n",
      "Epoch 56/550\n",
      "34/34 [==============================] - 0s 759us/step - loss: 1.9509 - accuracy: 0.3267\n",
      "Epoch 57/550\n",
      "34/34 [==============================] - 0s 690us/step - loss: 1.9485 - accuracy: 0.3402\n",
      "Epoch 58/550\n",
      "34/34 [==============================] - 0s 777us/step - loss: 1.9312 - accuracy: 0.3524\n",
      "Epoch 59/550\n",
      "34/34 [==============================] - 0s 795us/step - loss: 1.9187 - accuracy: 0.3634\n",
      "Epoch 60/550\n",
      "34/34 [==============================] - 0s 788us/step - loss: 1.9501 - accuracy: 0.3351\n",
      "Epoch 61/550\n",
      "34/34 [==============================] - 0s 725us/step - loss: 1.8996 - accuracy: 0.3673\n",
      "Epoch 62/550\n",
      "34/34 [==============================] - 0s 686us/step - loss: 1.9013 - accuracy: 0.3587\n",
      "Epoch 63/550\n",
      "34/34 [==============================] - 0s 800us/step - loss: 1.9056 - accuracy: 0.3827\n",
      "Epoch 64/550\n",
      "34/34 [==============================] - 0s 742us/step - loss: 1.8776 - accuracy: 0.3761\n",
      "Epoch 65/550\n",
      "34/34 [==============================] - 0s 634us/step - loss: 1.8910 - accuracy: 0.3536\n",
      "Epoch 66/550\n",
      "34/34 [==============================] - 0s 716us/step - loss: 1.8824 - accuracy: 0.3575\n",
      "Epoch 67/550\n",
      "34/34 [==============================] - 0s 699us/step - loss: 1.8807 - accuracy: 0.3622\n",
      "Epoch 68/550\n",
      "34/34 [==============================] - 0s 672us/step - loss: 1.8709 - accuracy: 0.3723\n",
      "Epoch 69/550\n",
      "34/34 [==============================] - 0s 836us/step - loss: 1.8402 - accuracy: 0.3874\n",
      "Epoch 70/550\n",
      "34/34 [==============================] - 0s 749us/step - loss: 1.8476 - accuracy: 0.3867\n",
      "Epoch 71/550\n",
      "34/34 [==============================] - 0s 684us/step - loss: 1.8792 - accuracy: 0.3544\n",
      "Epoch 72/550\n",
      "34/34 [==============================] - 0s 689us/step - loss: 1.8468 - accuracy: 0.3909\n",
      "Epoch 73/550\n",
      "34/34 [==============================] - 0s 722us/step - loss: 1.8516 - accuracy: 0.3653\n",
      "Epoch 74/550\n",
      "34/34 [==============================] - 0s 675us/step - loss: 1.8251 - accuracy: 0.3846\n",
      "Epoch 75/550\n",
      "34/34 [==============================] - 0s 746us/step - loss: 1.8224 - accuracy: 0.4011\n",
      "Epoch 76/550\n",
      "34/34 [==============================] - 0s 845us/step - loss: 1.8522 - accuracy: 0.3625\n",
      "Epoch 77/550\n",
      "34/34 [==============================] - 0s 737us/step - loss: 1.8220 - accuracy: 0.3873\n",
      "Epoch 78/550\n",
      "34/34 [==============================] - 0s 664us/step - loss: 1.8122 - accuracy: 0.3955\n",
      "Epoch 79/550\n",
      "34/34 [==============================] - 0s 586us/step - loss: 1.8330 - accuracy: 0.3923\n",
      "Epoch 80/550\n",
      "34/34 [==============================] - 0s 696us/step - loss: 1.7980 - accuracy: 0.3959\n",
      "Epoch 81/550\n",
      "34/34 [==============================] - 0s 645us/step - loss: 1.7849 - accuracy: 0.3918\n",
      "Epoch 82/550\n",
      "34/34 [==============================] - 0s 788us/step - loss: 1.8090 - accuracy: 0.3674\n",
      "Epoch 83/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.8021 - accuracy: 0.3891\n",
      "Epoch 84/550\n",
      "34/34 [==============================] - 0s 691us/step - loss: 1.7861 - accuracy: 0.4048\n",
      "Epoch 85/550\n",
      "34/34 [==============================] - 0s 703us/step - loss: 1.7484 - accuracy: 0.4105\n",
      "Epoch 86/550\n",
      "34/34 [==============================] - 0s 776us/step - loss: 1.7723 - accuracy: 0.4049\n",
      "Epoch 87/550\n",
      "34/34 [==============================] - 0s 707us/step - loss: 1.7723 - accuracy: 0.3731\n",
      "Epoch 88/550\n",
      "34/34 [==============================] - 0s 689us/step - loss: 1.7876 - accuracy: 0.3894\n",
      "Epoch 89/550\n",
      "34/34 [==============================] - 0s 750us/step - loss: 1.7624 - accuracy: 0.4101\n",
      "Epoch 90/550\n",
      "34/34 [==============================] - 0s 718us/step - loss: 1.7712 - accuracy: 0.4054\n",
      "Epoch 91/550\n",
      "34/34 [==============================] - 0s 751us/step - loss: 1.7404 - accuracy: 0.4201\n",
      "Epoch 92/550\n",
      "34/34 [==============================] - 0s 691us/step - loss: 1.7274 - accuracy: 0.4226\n",
      "Epoch 93/550\n",
      "34/34 [==============================] - 0s 779us/step - loss: 1.7372 - accuracy: 0.4291\n",
      "Epoch 94/550\n",
      "34/34 [==============================] - 0s 786us/step - loss: 1.7194 - accuracy: 0.4248\n",
      "Epoch 95/550\n",
      "34/34 [==============================] - 0s 726us/step - loss: 1.7378 - accuracy: 0.4071\n",
      "Epoch 96/550\n",
      "34/34 [==============================] - 0s 659us/step - loss: 1.7292 - accuracy: 0.4078\n",
      "Epoch 97/550\n",
      "34/34 [==============================] - 0s 929us/step - loss: 1.6958 - accuracy: 0.4298\n",
      "Epoch 98/550\n",
      "34/34 [==============================] - 0s 784us/step - loss: 1.7399 - accuracy: 0.4109\n",
      "Epoch 99/550\n",
      "34/34 [==============================] - 0s 853us/step - loss: 1.7032 - accuracy: 0.4327\n",
      "Epoch 100/550\n",
      "34/34 [==============================] - 0s 896us/step - loss: 1.7136 - accuracy: 0.4355\n",
      "Epoch 101/550\n",
      "34/34 [==============================] - 0s 766us/step - loss: 1.6948 - accuracy: 0.4405\n",
      "Epoch 102/550\n",
      "34/34 [==============================] - 0s 608us/step - loss: 1.7117 - accuracy: 0.4172\n",
      "Epoch 103/550\n",
      "34/34 [==============================] - 0s 738us/step - loss: 1.7055 - accuracy: 0.4120\n",
      "Epoch 104/550\n",
      "34/34 [==============================] - 0s 759us/step - loss: 1.7016 - accuracy: 0.4367\n",
      "Epoch 105/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.7175 - accuracy: 0.4077\n",
      "Epoch 106/550\n",
      "34/34 [==============================] - 0s 700us/step - loss: 1.6912 - accuracy: 0.4408\n",
      "Epoch 107/550\n",
      "34/34 [==============================] - 0s 765us/step - loss: 1.6799 - accuracy: 0.4252\n",
      "Epoch 108/550\n",
      "34/34 [==============================] - 0s 772us/step - loss: 1.6657 - accuracy: 0.4390\n",
      "Epoch 109/550\n",
      "34/34 [==============================] - 0s 701us/step - loss: 1.6699 - accuracy: 0.4398\n",
      "Epoch 110/550\n",
      "34/34 [==============================] - 0s 740us/step - loss: 1.6757 - accuracy: 0.4514\n",
      "Epoch 111/550\n",
      "34/34 [==============================] - 0s 717us/step - loss: 1.6451 - accuracy: 0.4490\n",
      "Epoch 112/550\n",
      "34/34 [==============================] - 0s 713us/step - loss: 1.6668 - accuracy: 0.4301\n",
      "Epoch 113/550\n",
      "34/34 [==============================] - 0s 701us/step - loss: 1.6338 - accuracy: 0.4390\n",
      "Epoch 114/550\n",
      "34/34 [==============================] - 0s 653us/step - loss: 1.6663 - accuracy: 0.4312\n",
      "Epoch 115/550\n",
      "34/34 [==============================] - 0s 629us/step - loss: 1.6324 - accuracy: 0.4443\n",
      "Epoch 116/550\n",
      "34/34 [==============================] - 0s 838us/step - loss: 1.6540 - accuracy: 0.4443\n",
      "Epoch 117/550\n",
      "34/34 [==============================] - 0s 712us/step - loss: 1.6489 - accuracy: 0.4184\n",
      "Epoch 118/550\n",
      "34/34 [==============================] - 0s 736us/step - loss: 1.6421 - accuracy: 0.4284\n",
      "Epoch 119/550\n",
      "34/34 [==============================] - 0s 633us/step - loss: 1.6042 - accuracy: 0.4421\n",
      "Epoch 120/550\n",
      "34/34 [==============================] - 0s 686us/step - loss: 1.5964 - accuracy: 0.4643\n",
      "Epoch 121/550\n",
      "34/34 [==============================] - 0s 764us/step - loss: 1.6278 - accuracy: 0.4533\n",
      "Epoch 122/550\n",
      "34/34 [==============================] - 0s 643us/step - loss: 1.5880 - accuracy: 0.4537\n",
      "Epoch 123/550\n",
      "34/34 [==============================] - 0s 834us/step - loss: 1.5988 - accuracy: 0.4514\n",
      "Epoch 124/550\n",
      "34/34 [==============================] - 0s 664us/step - loss: 1.5865 - accuracy: 0.4703\n",
      "Epoch 125/550\n",
      "34/34 [==============================] - 0s 773us/step - loss: 1.6090 - accuracy: 0.4562\n",
      "Epoch 126/550\n",
      "34/34 [==============================] - 0s 657us/step - loss: 1.5879 - accuracy: 0.4600\n",
      "Epoch 127/550\n",
      "34/34 [==============================] - 0s 774us/step - loss: 1.5880 - accuracy: 0.4722\n",
      "Epoch 128/550\n",
      "34/34 [==============================] - 0s 763us/step - loss: 1.5874 - accuracy: 0.4721\n",
      "Epoch 129/550\n",
      "34/34 [==============================] - 0s 646us/step - loss: 1.5887 - accuracy: 0.4531\n",
      "Epoch 130/550\n",
      "34/34 [==============================] - 0s 805us/step - loss: 1.5661 - accuracy: 0.4669\n",
      "Epoch 131/550\n",
      "34/34 [==============================] - 0s 629us/step - loss: 1.5905 - accuracy: 0.4824\n",
      "Epoch 132/550\n",
      "34/34 [==============================] - 0s 797us/step - loss: 1.5976 - accuracy: 0.4683\n",
      "Epoch 133/550\n",
      "34/34 [==============================] - 0s 651us/step - loss: 1.5800 - accuracy: 0.4778\n",
      "Epoch 134/550\n",
      "34/34 [==============================] - 0s 756us/step - loss: 1.5835 - accuracy: 0.4458\n",
      "Epoch 135/550\n",
      "34/34 [==============================] - 0s 650us/step - loss: 1.5648 - accuracy: 0.4694\n",
      "Epoch 136/550\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.6004 - accuracy: 0.4576\n",
      "Epoch 137/550\n",
      "34/34 [==============================] - 0s 726us/step - loss: 1.5515 - accuracy: 0.4755\n",
      "Epoch 138/550\n",
      "34/34 [==============================] - 0s 771us/step - loss: 1.5473 - accuracy: 0.4729\n",
      "Epoch 139/550\n",
      "34/34 [==============================] - 0s 672us/step - loss: 1.5337 - accuracy: 0.4892\n",
      "Epoch 140/550\n",
      "34/34 [==============================] - 0s 712us/step - loss: 1.5582 - accuracy: 0.4843\n",
      "Epoch 141/550\n",
      "34/34 [==============================] - 0s 769us/step - loss: 1.5017 - accuracy: 0.5159\n",
      "Epoch 142/550\n",
      "34/34 [==============================] - 0s 688us/step - loss: 1.5324 - accuracy: 0.5023\n",
      "Epoch 143/550\n",
      "34/34 [==============================] - 0s 779us/step - loss: 1.4858 - accuracy: 0.4972\n",
      "Epoch 144/550\n",
      "34/34 [==============================] - 0s 618us/step - loss: 1.5392 - accuracy: 0.4960\n",
      "Epoch 145/550\n",
      "34/34 [==============================] - 0s 740us/step - loss: 1.5500 - accuracy: 0.4752\n",
      "Epoch 146/550\n",
      "34/34 [==============================] - 0s 636us/step - loss: 1.4832 - accuracy: 0.4965\n",
      "Epoch 147/550\n",
      "34/34 [==============================] - 0s 763us/step - loss: 1.4698 - accuracy: 0.5213\n",
      "Epoch 148/550\n",
      "34/34 [==============================] - 0s 715us/step - loss: 1.5000 - accuracy: 0.5006\n",
      "Epoch 149/550\n",
      "34/34 [==============================] - 0s 908us/step - loss: 1.4885 - accuracy: 0.4814\n",
      "Epoch 150/550\n",
      "34/34 [==============================] - 0s 734us/step - loss: 1.4750 - accuracy: 0.5160\n",
      "Epoch 151/550\n",
      "34/34 [==============================] - 0s 758us/step - loss: 1.4813 - accuracy: 0.5221\n",
      "Epoch 152/550\n",
      "34/34 [==============================] - 0s 771us/step - loss: 1.4767 - accuracy: 0.5240\n",
      "Epoch 153/550\n",
      "34/34 [==============================] - 0s 831us/step - loss: 1.5011 - accuracy: 0.5122\n",
      "Epoch 154/550\n",
      "34/34 [==============================] - 0s 721us/step - loss: 1.5335 - accuracy: 0.4913\n",
      "Epoch 155/550\n",
      "34/34 [==============================] - 0s 674us/step - loss: 1.5122 - accuracy: 0.5046\n",
      "Epoch 156/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.4686 - accuracy: 0.5053\n",
      "Epoch 157/550\n",
      "34/34 [==============================] - 0s 780us/step - loss: 1.4806 - accuracy: 0.5170\n",
      "Epoch 158/550\n",
      "34/34 [==============================] - 0s 665us/step - loss: 1.4667 - accuracy: 0.4993\n",
      "Epoch 159/550\n",
      "34/34 [==============================] - 0s 853us/step - loss: 1.4991 - accuracy: 0.5209\n",
      "Epoch 160/550\n",
      "34/34 [==============================] - 0s 691us/step - loss: 1.4401 - accuracy: 0.5287\n",
      "Epoch 161/550\n",
      "34/34 [==============================] - 0s 930us/step - loss: 1.4451 - accuracy: 0.5180\n",
      "Epoch 162/550\n",
      "34/34 [==============================] - 0s 640us/step - loss: 1.4748 - accuracy: 0.5190\n",
      "Epoch 163/550\n",
      "34/34 [==============================] - 0s 876us/step - loss: 1.4642 - accuracy: 0.5248\n",
      "Epoch 164/550\n",
      "34/34 [==============================] - 0s 643us/step - loss: 1.4501 - accuracy: 0.4920\n",
      "Epoch 165/550\n",
      "34/34 [==============================] - 0s 840us/step - loss: 1.4697 - accuracy: 0.5086\n",
      "Epoch 166/550\n",
      "34/34 [==============================] - 0s 659us/step - loss: 1.4504 - accuracy: 0.5195\n",
      "Epoch 167/550\n",
      "34/34 [==============================] - 0s 668us/step - loss: 1.4889 - accuracy: 0.5074\n",
      "Epoch 168/550\n",
      "34/34 [==============================] - 0s 734us/step - loss: 1.4843 - accuracy: 0.5027\n",
      "Epoch 169/550\n",
      "34/34 [==============================] - 0s 649us/step - loss: 1.4635 - accuracy: 0.5064\n",
      "Epoch 170/550\n",
      "34/34 [==============================] - 0s 663us/step - loss: 1.4409 - accuracy: 0.5270\n",
      "Epoch 171/550\n",
      "34/34 [==============================] - 0s 844us/step - loss: 1.4479 - accuracy: 0.5111\n",
      "Epoch 172/550\n",
      "34/34 [==============================] - 0s 699us/step - loss: 1.4326 - accuracy: 0.5192\n",
      "Epoch 173/550\n",
      "34/34 [==============================] - 0s 726us/step - loss: 1.4619 - accuracy: 0.5074\n",
      "Epoch 174/550\n",
      "34/34 [==============================] - 0s 818us/step - loss: 1.4479 - accuracy: 0.5142\n",
      "Epoch 175/550\n",
      "34/34 [==============================] - 0s 642us/step - loss: 1.4194 - accuracy: 0.5367\n",
      "Epoch 176/550\n",
      "34/34 [==============================] - 0s 813us/step - loss: 1.4017 - accuracy: 0.5430\n",
      "Epoch 177/550\n",
      "34/34 [==============================] - 0s 663us/step - loss: 1.3796 - accuracy: 0.5468\n",
      "Epoch 178/550\n",
      "34/34 [==============================] - 0s 709us/step - loss: 1.3895 - accuracy: 0.5450\n",
      "Epoch 179/550\n",
      "34/34 [==============================] - 0s 801us/step - loss: 1.4483 - accuracy: 0.5127\n",
      "Epoch 180/550\n",
      "34/34 [==============================] - 0s 670us/step - loss: 1.3720 - accuracy: 0.5612\n",
      "Epoch 181/550\n",
      "34/34 [==============================] - 0s 616us/step - loss: 1.4258 - accuracy: 0.5403\n",
      "Epoch 182/550\n",
      "34/34 [==============================] - 0s 766us/step - loss: 1.4118 - accuracy: 0.5198\n",
      "Epoch 183/550\n",
      "34/34 [==============================] - 0s 713us/step - loss: 1.4355 - accuracy: 0.5351\n",
      "Epoch 184/550\n",
      "34/34 [==============================] - 0s 649us/step - loss: 1.4689 - accuracy: 0.5024\n",
      "Epoch 185/550\n",
      "34/34 [==============================] - 0s 730us/step - loss: 1.4156 - accuracy: 0.4970\n",
      "Epoch 186/550\n",
      "34/34 [==============================] - 0s 691us/step - loss: 1.3742 - accuracy: 0.5412\n",
      "Epoch 187/550\n",
      "34/34 [==============================] - 0s 597us/step - loss: 1.4186 - accuracy: 0.4998\n",
      "Epoch 188/550\n",
      "34/34 [==============================] - 0s 870us/step - loss: 1.3984 - accuracy: 0.5336\n",
      "Epoch 189/550\n",
      "34/34 [==============================] - 0s 736us/step - loss: 1.3775 - accuracy: 0.5510\n",
      "Epoch 190/550\n",
      "34/34 [==============================] - 0s 909us/step - loss: 1.3716 - accuracy: 0.5312\n",
      "Epoch 191/550\n",
      "34/34 [==============================] - 0s 713us/step - loss: 1.3664 - accuracy: 0.5373\n",
      "Epoch 192/550\n",
      "34/34 [==============================] - 0s 780us/step - loss: 1.4075 - accuracy: 0.5279\n",
      "Epoch 193/550\n",
      "34/34 [==============================] - 0s 706us/step - loss: 1.4161 - accuracy: 0.5170\n",
      "Epoch 194/550\n",
      "34/34 [==============================] - 0s 736us/step - loss: 1.4027 - accuracy: 0.5259\n",
      "Epoch 195/550\n",
      "34/34 [==============================] - 0s 820us/step - loss: 1.3765 - accuracy: 0.5306\n",
      "Epoch 196/550\n",
      "34/34 [==============================] - 0s 708us/step - loss: 1.3481 - accuracy: 0.5538\n",
      "Epoch 197/550\n",
      "34/34 [==============================] - 0s 803us/step - loss: 1.3439 - accuracy: 0.5583\n",
      "Epoch 198/550\n",
      "34/34 [==============================] - 0s 697us/step - loss: 1.3967 - accuracy: 0.5427\n",
      "Epoch 199/550\n",
      "34/34 [==============================] - 0s 902us/step - loss: 1.3825 - accuracy: 0.5392\n",
      "Epoch 200/550\n",
      "34/34 [==============================] - 0s 631us/step - loss: 1.3494 - accuracy: 0.5437\n",
      "Epoch 201/550\n",
      "34/34 [==============================] - 0s 798us/step - loss: 1.3868 - accuracy: 0.5400\n",
      "Epoch 202/550\n",
      "34/34 [==============================] - 0s 673us/step - loss: 1.4051 - accuracy: 0.5205\n",
      "Epoch 203/550\n",
      "34/34 [==============================] - 0s 635us/step - loss: 1.3582 - accuracy: 0.5563\n",
      "Epoch 204/550\n",
      "34/34 [==============================] - 0s 931us/step - loss: 1.3748 - accuracy: 0.5536\n",
      "Epoch 205/550\n",
      "34/34 [==============================] - 0s 697us/step - loss: 1.3629 - accuracy: 0.5531\n",
      "Epoch 206/550\n",
      "34/34 [==============================] - 0s 782us/step - loss: 1.3393 - accuracy: 0.5752\n",
      "Epoch 207/550\n",
      "34/34 [==============================] - 0s 740us/step - loss: 1.3442 - accuracy: 0.5613\n",
      "Epoch 208/550\n",
      "34/34 [==============================] - 0s 774us/step - loss: 1.3020 - accuracy: 0.5527\n",
      "Epoch 209/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.3143 - accuracy: 0.6015\n",
      "Epoch 210/550\n",
      "34/34 [==============================] - 0s 936us/step - loss: 1.3445 - accuracy: 0.5655\n",
      "Epoch 211/550\n",
      "34/34 [==============================] - 0s 668us/step - loss: 1.2634 - accuracy: 0.6053\n",
      "Epoch 212/550\n",
      "34/34 [==============================] - 0s 709us/step - loss: 1.2708 - accuracy: 0.6049\n",
      "Epoch 213/550\n",
      "34/34 [==============================] - 0s 714us/step - loss: 1.3057 - accuracy: 0.5731\n",
      "Epoch 214/550\n",
      "34/34 [==============================] - 0s 653us/step - loss: 1.3361 - accuracy: 0.5736\n",
      "Epoch 215/550\n",
      "34/34 [==============================] - 0s 694us/step - loss: 1.3544 - accuracy: 0.5605\n",
      "Epoch 216/550\n",
      "34/34 [==============================] - 0s 680us/step - loss: 1.3623 - accuracy: 0.5599\n",
      "Epoch 217/550\n",
      "34/34 [==============================] - 0s 893us/step - loss: 1.3522 - accuracy: 0.5650\n",
      "Epoch 218/550\n",
      "34/34 [==============================] - 0s 695us/step - loss: 1.3363 - accuracy: 0.5431\n",
      "Epoch 219/550\n",
      "34/34 [==============================] - 0s 809us/step - loss: 1.3356 - accuracy: 0.5625\n",
      "Epoch 220/550\n",
      "34/34 [==============================] - 0s 769us/step - loss: 1.2749 - accuracy: 0.5803\n",
      "Epoch 221/550\n",
      "34/34 [==============================] - 0s 702us/step - loss: 1.3087 - accuracy: 0.5844\n",
      "Epoch 222/550\n",
      "34/34 [==============================] - 0s 761us/step - loss: 1.2534 - accuracy: 0.6059\n",
      "Epoch 223/550\n",
      "34/34 [==============================] - 0s 961us/step - loss: 1.2930 - accuracy: 0.5841\n",
      "Epoch 224/550\n",
      "34/34 [==============================] - 0s 917us/step - loss: 1.2892 - accuracy: 0.5855\n",
      "Epoch 225/550\n",
      "34/34 [==============================] - 0s 905us/step - loss: 1.2565 - accuracy: 0.6313\n",
      "Epoch 226/550\n",
      "34/34 [==============================] - 0s 949us/step - loss: 1.2747 - accuracy: 0.5777\n",
      "Epoch 227/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.2945 - accuracy: 0.5767\n",
      "Epoch 228/550\n",
      "34/34 [==============================] - 0s 836us/step - loss: 1.3448 - accuracy: 0.5543\n",
      "Epoch 229/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.2597 - accuracy: 0.5969\n",
      "Epoch 230/550\n",
      "34/34 [==============================] - 0s 778us/step - loss: 1.2767 - accuracy: 0.5874\n",
      "Epoch 231/550\n",
      "34/34 [==============================] - 0s 849us/step - loss: 1.2985 - accuracy: 0.5661\n",
      "Epoch 232/550\n",
      "34/34 [==============================] - 0s 847us/step - loss: 1.2761 - accuracy: 0.5888\n",
      "Epoch 233/550\n",
      "34/34 [==============================] - 0s 797us/step - loss: 1.2938 - accuracy: 0.5665\n",
      "Epoch 234/550\n",
      "34/34 [==============================] - 0s 983us/step - loss: 1.2578 - accuracy: 0.6222\n",
      "Epoch 235/550\n",
      "34/34 [==============================] - 0s 747us/step - loss: 1.2749 - accuracy: 0.5821\n",
      "Epoch 236/550\n",
      "34/34 [==============================] - 0s 785us/step - loss: 1.2372 - accuracy: 0.6081\n",
      "Epoch 237/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.2227 - accuracy: 0.5965\n",
      "Epoch 238/550\n",
      "34/34 [==============================] - 0s 760us/step - loss: 1.2845 - accuracy: 0.5887\n",
      "Epoch 239/550\n",
      "34/34 [==============================] - 0s 793us/step - loss: 1.3029 - accuracy: 0.5772\n",
      "Epoch 240/550\n",
      "34/34 [==============================] - 0s 952us/step - loss: 1.2464 - accuracy: 0.6167\n",
      "Epoch 241/550\n",
      "34/34 [==============================] - 0s 771us/step - loss: 1.2426 - accuracy: 0.5974\n",
      "Epoch 242/550\n",
      "34/34 [==============================] - 0s 912us/step - loss: 1.2164 - accuracy: 0.6120\n",
      "Epoch 243/550\n",
      "34/34 [==============================] - 0s 918us/step - loss: 1.2740 - accuracy: 0.5869\n",
      "Epoch 244/550\n",
      "34/34 [==============================] - 0s 781us/step - loss: 1.2382 - accuracy: 0.5825\n",
      "Epoch 245/550\n",
      "34/34 [==============================] - 0s 845us/step - loss: 1.2330 - accuracy: 0.5869\n",
      "Epoch 246/550\n",
      "34/34 [==============================] - 0s 795us/step - loss: 1.2576 - accuracy: 0.6018\n",
      "Epoch 247/550\n",
      "34/34 [==============================] - 0s 993us/step - loss: 1.2365 - accuracy: 0.6012\n",
      "Epoch 248/550\n",
      "34/34 [==============================] - 0s 878us/step - loss: 1.2092 - accuracy: 0.6225\n",
      "Epoch 249/550\n",
      "34/34 [==============================] - 0s 766us/step - loss: 1.2613 - accuracy: 0.6082\n",
      "Epoch 250/550\n",
      "34/34 [==============================] - 0s 807us/step - loss: 1.2245 - accuracy: 0.6141\n",
      "Epoch 251/550\n",
      "34/34 [==============================] - 0s 962us/step - loss: 1.2205 - accuracy: 0.6029\n",
      "Epoch 252/550\n",
      "34/34 [==============================] - 0s 726us/step - loss: 1.2658 - accuracy: 0.5966\n",
      "Epoch 253/550\n",
      "34/34 [==============================] - 0s 776us/step - loss: 1.2538 - accuracy: 0.5845\n",
      "Epoch 254/550\n",
      "34/34 [==============================] - 0s 906us/step - loss: 1.2732 - accuracy: 0.5553\n",
      "Epoch 255/550\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.1957 - accuracy: 0.6218\n",
      "Epoch 256/550\n",
      "34/34 [==============================] - 0s 761us/step - loss: 1.2135 - accuracy: 0.6341\n",
      "Epoch 257/550\n",
      "34/34 [==============================] - 0s 766us/step - loss: 1.1936 - accuracy: 0.6141\n",
      "Epoch 258/550\n",
      "34/34 [==============================] - 0s 871us/step - loss: 1.1904 - accuracy: 0.6194\n",
      "Epoch 259/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.1601 - accuracy: 0.6419\n",
      "Epoch 260/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.1901 - accuracy: 0.6299\n",
      "Epoch 261/550\n",
      "34/34 [==============================] - 0s 835us/step - loss: 1.2091 - accuracy: 0.6240\n",
      "Epoch 262/550\n",
      "34/34 [==============================] - 0s 924us/step - loss: 1.1689 - accuracy: 0.6325\n",
      "Epoch 263/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.2307 - accuracy: 0.6117\n",
      "Epoch 264/550\n",
      "34/34 [==============================] - 0s 743us/step - loss: 1.2046 - accuracy: 0.6183\n",
      "Epoch 265/550\n",
      "34/34 [==============================] - 0s 866us/step - loss: 1.1899 - accuracy: 0.6276\n",
      "Epoch 266/550\n",
      "34/34 [==============================] - 0s 919us/step - loss: 1.2040 - accuracy: 0.6276\n",
      "Epoch 267/550\n",
      "34/34 [==============================] - 0s 779us/step - loss: 1.1828 - accuracy: 0.6493\n",
      "Epoch 268/550\n",
      "34/34 [==============================] - 0s 792us/step - loss: 1.1682 - accuracy: 0.6273\n",
      "Epoch 269/550\n",
      "34/34 [==============================] - 0s 798us/step - loss: 1.2467 - accuracy: 0.6142\n",
      "Epoch 270/550\n",
      "34/34 [==============================] - 0s 782us/step - loss: 1.2470 - accuracy: 0.5950\n",
      "Epoch 271/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.1963 - accuracy: 0.6169\n",
      "Epoch 272/550\n",
      "34/34 [==============================] - 0s 945us/step - loss: 1.1871 - accuracy: 0.6286\n",
      "Epoch 273/550\n",
      "34/34 [==============================] - 0s 776us/step - loss: 1.2175 - accuracy: 0.6050\n",
      "Epoch 274/550\n",
      "34/34 [==============================] - 0s 783us/step - loss: 1.1479 - accuracy: 0.6532\n",
      "Epoch 275/550\n",
      "34/34 [==============================] - 0s 881us/step - loss: 1.1883 - accuracy: 0.6198\n",
      "Epoch 276/550\n",
      "34/34 [==============================] - 0s 925us/step - loss: 1.1607 - accuracy: 0.6275\n",
      "Epoch 277/550\n",
      "34/34 [==============================] - 0s 773us/step - loss: 1.1683 - accuracy: 0.6354\n",
      "Epoch 278/550\n",
      "34/34 [==============================] - 0s 930us/step - loss: 1.1946 - accuracy: 0.6264\n",
      "Epoch 279/550\n",
      "34/34 [==============================] - 0s 939us/step - loss: 1.2129 - accuracy: 0.6288\n",
      "Epoch 280/550\n",
      "34/34 [==============================] - 0s 821us/step - loss: 1.1835 - accuracy: 0.6424\n",
      "Epoch 281/550\n",
      "34/34 [==============================] - 0s 777us/step - loss: 1.2068 - accuracy: 0.6492\n",
      "Epoch 282/550\n",
      "34/34 [==============================] - 0s 812us/step - loss: 1.1906 - accuracy: 0.6111\n",
      "Epoch 283/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.1778 - accuracy: 0.6202\n",
      "Epoch 284/550\n",
      "34/34 [==============================] - 0s 800us/step - loss: 1.1822 - accuracy: 0.6212\n",
      "Epoch 285/550\n",
      "34/34 [==============================] - 0s 891us/step - loss: 1.1386 - accuracy: 0.6395\n",
      "Epoch 286/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.1616 - accuracy: 0.6170\n",
      "Epoch 287/550\n",
      "34/34 [==============================] - 0s 926us/step - loss: 1.1428 - accuracy: 0.6251\n",
      "Epoch 288/550\n",
      "34/34 [==============================] - 0s 776us/step - loss: 1.1536 - accuracy: 0.6370\n",
      "Epoch 289/550\n",
      "34/34 [==============================] - 0s 960us/step - loss: 1.1669 - accuracy: 0.6356\n",
      "Epoch 290/550\n",
      "34/34 [==============================] - 0s 921us/step - loss: 1.1592 - accuracy: 0.6390\n",
      "Epoch 291/550\n",
      "34/34 [==============================] - 0s 792us/step - loss: 1.1898 - accuracy: 0.6258\n",
      "Epoch 292/550\n",
      "34/34 [==============================] - 0s 952us/step - loss: 1.1191 - accuracy: 0.6224\n",
      "Epoch 293/550\n",
      "34/34 [==============================] - 0s 884us/step - loss: 1.1126 - accuracy: 0.6479\n",
      "Epoch 294/550\n",
      "34/34 [==============================] - 0s 813us/step - loss: 1.1360 - accuracy: 0.6511\n",
      "Epoch 295/550\n",
      "34/34 [==============================] - 0s 845us/step - loss: 1.1269 - accuracy: 0.6558\n",
      "Epoch 296/550\n",
      "34/34 [==============================] - 0s 951us/step - loss: 1.1569 - accuracy: 0.6381\n",
      "Epoch 297/550\n",
      "34/34 [==============================] - 0s 840us/step - loss: 1.1180 - accuracy: 0.6405\n",
      "Epoch 298/550\n",
      "34/34 [==============================] - 0s 823us/step - loss: 1.1377 - accuracy: 0.6485\n",
      "Epoch 299/550\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.1021 - accuracy: 0.6413\n",
      "Epoch 300/550\n",
      "34/34 [==============================] - 0s 820us/step - loss: 1.1065 - accuracy: 0.6609\n",
      "Epoch 301/550\n",
      "34/34 [==============================] - 0s 814us/step - loss: 1.1153 - accuracy: 0.6384\n",
      "Epoch 302/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.1459 - accuracy: 0.6525\n",
      "Epoch 303/550\n",
      "34/34 [==============================] - 0s 893us/step - loss: 1.1079 - accuracy: 0.6434\n",
      "Epoch 304/550\n",
      "34/34 [==============================] - 0s 802us/step - loss: 1.0988 - accuracy: 0.6388\n",
      "Epoch 305/550\n",
      "34/34 [==============================] - 0s 891us/step - loss: 1.1377 - accuracy: 0.6412\n",
      "Epoch 306/550\n",
      "34/34 [==============================] - 0s 889us/step - loss: 1.1047 - accuracy: 0.6674\n",
      "Epoch 307/550\n",
      "34/34 [==============================] - 0s 816us/step - loss: 1.1233 - accuracy: 0.6480\n",
      "Epoch 308/550\n",
      "34/34 [==============================] - 0s 864us/step - loss: 1.0934 - accuracy: 0.6617\n",
      "Epoch 309/550\n",
      "34/34 [==============================] - 0s 944us/step - loss: 1.1043 - accuracy: 0.6472\n",
      "Epoch 310/550\n",
      "34/34 [==============================] - 0s 820us/step - loss: 1.1189 - accuracy: 0.6409\n",
      "Epoch 311/550\n",
      "34/34 [==============================] - 0s 764us/step - loss: 1.1100 - accuracy: 0.6726\n",
      "Epoch 312/550\n",
      "34/34 [==============================] - 0s 769us/step - loss: 1.1235 - accuracy: 0.6328\n",
      "Epoch 313/550\n",
      "34/34 [==============================] - 0s 811us/step - loss: 1.0787 - accuracy: 0.6618\n",
      "Epoch 314/550\n",
      "34/34 [==============================] - 0s 986us/step - loss: 1.1235 - accuracy: 0.6381\n",
      "Epoch 315/550\n",
      "34/34 [==============================] - 0s 808us/step - loss: 1.0425 - accuracy: 0.6898\n",
      "Epoch 316/550\n",
      "34/34 [==============================] - 0s 783us/step - loss: 1.0846 - accuracy: 0.6602\n",
      "Epoch 317/550\n",
      "34/34 [==============================] - 0s 869us/step - loss: 1.1249 - accuracy: 0.6198\n",
      "Epoch 318/550\n",
      "34/34 [==============================] - 0s 865us/step - loss: 1.1274 - accuracy: 0.6597\n",
      "Epoch 319/550\n",
      "34/34 [==============================] - 0s 810us/step - loss: 1.1369 - accuracy: 0.6502\n",
      "Epoch 320/550\n",
      "34/34 [==============================] - 0s 765us/step - loss: 1.1187 - accuracy: 0.6578\n",
      "Epoch 321/550\n",
      "34/34 [==============================] - 0s 811us/step - loss: 1.0911 - accuracy: 0.6530\n",
      "Epoch 322/550\n",
      "34/34 [==============================] - 0s 932us/step - loss: 1.1019 - accuracy: 0.6490\n",
      "Epoch 323/550\n",
      "34/34 [==============================] - 0s 811us/step - loss: 1.1030 - accuracy: 0.6575\n",
      "Epoch 324/550\n",
      "34/34 [==============================] - 0s 768us/step - loss: 1.0625 - accuracy: 0.6718\n",
      "Epoch 325/550\n",
      "34/34 [==============================] - 0s 895us/step - loss: 1.0828 - accuracy: 0.6574\n",
      "Epoch 326/550\n",
      "34/34 [==============================] - 0s 888us/step - loss: 1.0467 - accuracy: 0.6680\n",
      "Epoch 327/550\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.0806 - accuracy: 0.6653\n",
      "Epoch 328/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0823 - accuracy: 0.6588\n",
      "Epoch 329/550\n",
      "34/34 [==============================] - 0s 803us/step - loss: 1.0874 - accuracy: 0.6582\n",
      "Epoch 330/550\n",
      "34/34 [==============================] - 0s 764us/step - loss: 1.0896 - accuracy: 0.6504\n",
      "Epoch 331/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0755 - accuracy: 0.6747\n",
      "Epoch 332/550\n",
      "34/34 [==============================] - 0s 874us/step - loss: 1.0695 - accuracy: 0.6719\n",
      "Epoch 333/550\n",
      "34/34 [==============================] - 0s 773us/step - loss: 1.0512 - accuracy: 0.6790\n",
      "Epoch 334/550\n",
      "34/34 [==============================] - 0s 917us/step - loss: 1.0966 - accuracy: 0.6630\n",
      "Epoch 335/550\n",
      "34/34 [==============================] - 0s 874us/step - loss: 1.0000 - accuracy: 0.6840\n",
      "Epoch 336/550\n",
      "34/34 [==============================] - 0s 808us/step - loss: 1.0576 - accuracy: 0.6674\n",
      "Epoch 337/550\n",
      "34/34 [==============================] - 0s 763us/step - loss: 1.0311 - accuracy: 0.6736\n",
      "Epoch 338/550\n",
      "34/34 [==============================] - 0s 775us/step - loss: 1.0929 - accuracy: 0.6792\n",
      "Epoch 339/550\n",
      "34/34 [==============================] - 0s 802us/step - loss: 1.0364 - accuracy: 0.6762\n",
      "Epoch 340/550\n",
      "34/34 [==============================] - 0s 832us/step - loss: 1.0430 - accuracy: 0.6896\n",
      "Epoch 341/550\n",
      "34/34 [==============================] - 0s 779us/step - loss: 1.0363 - accuracy: 0.6794\n",
      "Epoch 342/550\n",
      "34/34 [==============================] - 0s 800us/step - loss: 1.0673 - accuracy: 0.6644\n",
      "Epoch 343/550\n",
      "34/34 [==============================] - 0s 815us/step - loss: 1.0566 - accuracy: 0.6714\n",
      "Epoch 344/550\n",
      "34/34 [==============================] - 0s 986us/step - loss: 1.0467 - accuracy: 0.6863\n",
      "Epoch 345/550\n",
      "34/34 [==============================] - 0s 782us/step - loss: 1.0200 - accuracy: 0.7097\n",
      "Epoch 346/550\n",
      "34/34 [==============================] - 0s 813us/step - loss: 1.0249 - accuracy: 0.6793\n",
      "Epoch 347/550\n",
      "34/34 [==============================] - 0s 971us/step - loss: 1.0924 - accuracy: 0.6629\n",
      "Epoch 348/550\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 1.0596 - accuracy: 0.6659\n",
      "Epoch 349/550\n",
      "34/34 [==============================] - 0s 828us/step - loss: 1.0451 - accuracy: 0.6803\n",
      "Epoch 350/550\n",
      "34/34 [==============================] - 0s 766us/step - loss: 1.0211 - accuracy: 0.7008\n",
      "Epoch 351/550\n",
      "34/34 [==============================] - 0s 782us/step - loss: 0.9925 - accuracy: 0.7041\n",
      "Epoch 352/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0749 - accuracy: 0.6583\n",
      "Epoch 353/550\n",
      "34/34 [==============================] - 0s 900us/step - loss: 1.0418 - accuracy: 0.6588\n",
      "Epoch 354/550\n",
      "34/34 [==============================] - 0s 807us/step - loss: 1.0484 - accuracy: 0.6839\n",
      "Epoch 355/550\n",
      "34/34 [==============================] - 0s 795us/step - loss: 1.0490 - accuracy: 0.6922\n",
      "Epoch 356/550\n",
      "34/34 [==============================] - 0s 923us/step - loss: 1.0000 - accuracy: 0.6883\n",
      "Epoch 357/550\n",
      "34/34 [==============================] - 0s 889us/step - loss: 1.0301 - accuracy: 0.6840\n",
      "Epoch 358/550\n",
      "34/34 [==============================] - 0s 746us/step - loss: 0.9840 - accuracy: 0.7033\n",
      "Epoch 359/550\n",
      "34/34 [==============================] - 0s 694us/step - loss: 1.0262 - accuracy: 0.6874\n",
      "Epoch 360/550\n",
      "34/34 [==============================] - 0s 931us/step - loss: 1.0261 - accuracy: 0.6886\n",
      "Epoch 361/550\n",
      "34/34 [==============================] - 0s 950us/step - loss: 1.0525 - accuracy: 0.6814\n",
      "Epoch 362/550\n",
      "34/34 [==============================] - 0s 795us/step - loss: 1.0374 - accuracy: 0.6808\n",
      "Epoch 363/550\n",
      "34/34 [==============================] - 0s 761us/step - loss: 1.0388 - accuracy: 0.6834\n",
      "Epoch 364/550\n",
      "34/34 [==============================] - 0s 863us/step - loss: 1.0615 - accuracy: 0.6952\n",
      "Epoch 365/550\n",
      "34/34 [==============================] - 0s 922us/step - loss: 1.0555 - accuracy: 0.6411\n",
      "Epoch 366/550\n",
      "34/34 [==============================] - 0s 949us/step - loss: 1.0067 - accuracy: 0.6897\n",
      "Epoch 367/550\n",
      "34/34 [==============================] - 0s 790us/step - loss: 0.9951 - accuracy: 0.6981\n",
      "Epoch 368/550\n",
      "34/34 [==============================] - 0s 711us/step - loss: 1.0207 - accuracy: 0.6804\n",
      "Epoch 369/550\n",
      "34/34 [==============================] - 0s 941us/step - loss: 1.0240 - accuracy: 0.6752\n",
      "Epoch 370/550\n",
      "34/34 [==============================] - 0s 902us/step - loss: 1.0139 - accuracy: 0.6852\n",
      "Epoch 371/550\n",
      "34/34 [==============================] - 0s 759us/step - loss: 0.9929 - accuracy: 0.7184\n",
      "Epoch 372/550\n",
      "34/34 [==============================] - 0s 714us/step - loss: 0.9727 - accuracy: 0.7062\n",
      "Epoch 373/550\n",
      "34/34 [==============================] - 0s 745us/step - loss: 0.9745 - accuracy: 0.7034\n",
      "Epoch 374/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 1.0704 - accuracy: 0.6739\n",
      "Epoch 375/550\n",
      "34/34 [==============================] - 0s 796us/step - loss: 1.0032 - accuracy: 0.6854\n",
      "Epoch 376/550\n",
      "34/34 [==============================] - 0s 731us/step - loss: 1.0097 - accuracy: 0.7102\n",
      "Epoch 377/550\n",
      "34/34 [==============================] - 0s 686us/step - loss: 1.0243 - accuracy: 0.6938\n",
      "Epoch 378/550\n",
      "34/34 [==============================] - 0s 924us/step - loss: 0.9963 - accuracy: 0.7027\n",
      "Epoch 379/550\n",
      "34/34 [==============================] - 0s 975us/step - loss: 0.9456 - accuracy: 0.7278\n",
      "Epoch 380/550\n",
      "34/34 [==============================] - 0s 819us/step - loss: 0.9851 - accuracy: 0.6872\n",
      "Epoch 381/550\n",
      "34/34 [==============================] - 0s 815us/step - loss: 0.9637 - accuracy: 0.7113\n",
      "Epoch 382/550\n",
      "34/34 [==============================] - 0s 852us/step - loss: 0.9693 - accuracy: 0.6919\n",
      "Epoch 383/550\n",
      "34/34 [==============================] - 0s 957us/step - loss: 1.0186 - accuracy: 0.6919\n",
      "Epoch 384/550\n",
      "34/34 [==============================] - 0s 854us/step - loss: 0.9677 - accuracy: 0.7090\n",
      "Epoch 385/550\n",
      "34/34 [==============================] - 0s 792us/step - loss: 0.9968 - accuracy: 0.7039\n",
      "Epoch 386/550\n",
      "34/34 [==============================] - 0s 753us/step - loss: 0.9355 - accuracy: 0.7177\n",
      "Epoch 387/550\n",
      "34/34 [==============================] - 0s 907us/step - loss: 0.9397 - accuracy: 0.7199\n",
      "Epoch 388/550\n",
      "34/34 [==============================] - 0s 933us/step - loss: 0.9725 - accuracy: 0.7119\n",
      "Epoch 389/550\n",
      "34/34 [==============================] - 0s 717us/step - loss: 0.9905 - accuracy: 0.7022\n",
      "Epoch 390/550\n",
      "34/34 [==============================] - 0s 685us/step - loss: 0.9685 - accuracy: 0.7005\n",
      "Epoch 391/550\n",
      "34/34 [==============================] - 0s 895us/step - loss: 1.0007 - accuracy: 0.6949\n",
      "Epoch 392/550\n",
      "34/34 [==============================] - 0s 972us/step - loss: 0.9499 - accuracy: 0.7128\n",
      "Epoch 393/550\n",
      "34/34 [==============================] - 0s 818us/step - loss: 0.9659 - accuracy: 0.7101\n",
      "Epoch 394/550\n",
      "34/34 [==============================] - 0s 858us/step - loss: 0.9413 - accuracy: 0.7027\n",
      "Epoch 395/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9225 - accuracy: 0.7137\n",
      "Epoch 396/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9639 - accuracy: 0.7139\n",
      "Epoch 397/550\n",
      "34/34 [==============================] - 0s 745us/step - loss: 0.9463 - accuracy: 0.7303\n",
      "Epoch 398/550\n",
      "34/34 [==============================] - 0s 808us/step - loss: 0.9391 - accuracy: 0.7232\n",
      "Epoch 399/550\n",
      "34/34 [==============================] - 0s 908us/step - loss: 0.9347 - accuracy: 0.7233\n",
      "Epoch 400/550\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.9640 - accuracy: 0.7127\n",
      "Epoch 401/550\n",
      "34/34 [==============================] - 0s 836us/step - loss: 0.9616 - accuracy: 0.7206\n",
      "Epoch 402/550\n",
      "34/34 [==============================] - 0s 858us/step - loss: 0.9364 - accuracy: 0.7165\n",
      "Epoch 403/550\n",
      "34/34 [==============================] - 0s 937us/step - loss: 0.9100 - accuracy: 0.7362\n",
      "Epoch 404/550\n",
      "34/34 [==============================] - 0s 896us/step - loss: 0.9418 - accuracy: 0.7208\n",
      "Epoch 405/550\n",
      "34/34 [==============================] - 0s 935us/step - loss: 0.9176 - accuracy: 0.7296\n",
      "Epoch 406/550\n",
      "34/34 [==============================] - 0s 832us/step - loss: 0.9098 - accuracy: 0.7216\n",
      "Epoch 407/550\n",
      "34/34 [==============================] - 0s 835us/step - loss: 0.9180 - accuracy: 0.7219\n",
      "Epoch 408/550\n",
      "34/34 [==============================] - 0s 835us/step - loss: 0.8705 - accuracy: 0.7257\n",
      "Epoch 409/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9544 - accuracy: 0.7194\n",
      "Epoch 410/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9033 - accuracy: 0.7456\n",
      "Epoch 411/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9807 - accuracy: 0.7068\n",
      "Epoch 412/550\n",
      "34/34 [==============================] - 0s 911us/step - loss: 0.9678 - accuracy: 0.7166\n",
      "Epoch 413/550\n",
      "34/34 [==============================] - 0s 795us/step - loss: 0.9131 - accuracy: 0.7316\n",
      "Epoch 414/550\n",
      "34/34 [==============================] - 0s 785us/step - loss: 0.9898 - accuracy: 0.6979\n",
      "Epoch 415/550\n",
      "34/34 [==============================] - 0s 978us/step - loss: 0.9279 - accuracy: 0.7310\n",
      "Epoch 416/550\n",
      "34/34 [==============================] - 0s 839us/step - loss: 0.9410 - accuracy: 0.7183\n",
      "Epoch 417/550\n",
      "34/34 [==============================] - 0s 811us/step - loss: 0.9379 - accuracy: 0.7150\n",
      "Epoch 418/550\n",
      "34/34 [==============================] - 0s 805us/step - loss: 0.9104 - accuracy: 0.7339\n",
      "Epoch 419/550\n",
      "34/34 [==============================] - 0s 992us/step - loss: 0.9222 - accuracy: 0.7210\n",
      "Epoch 420/550\n",
      "34/34 [==============================] - 0s 960us/step - loss: 0.8898 - accuracy: 0.7335\n",
      "Epoch 421/550\n",
      "34/34 [==============================] - 0s 749us/step - loss: 0.9317 - accuracy: 0.7288\n",
      "Epoch 422/550\n",
      "34/34 [==============================] - 0s 745us/step - loss: 0.9391 - accuracy: 0.7052\n",
      "Epoch 423/550\n",
      "34/34 [==============================] - 0s 723us/step - loss: 0.9439 - accuracy: 0.7215\n",
      "Epoch 424/550\n",
      "34/34 [==============================] - 0s 921us/step - loss: 0.9440 - accuracy: 0.7178\n",
      "Epoch 425/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9430 - accuracy: 0.7251\n",
      "Epoch 426/550\n",
      "34/34 [==============================] - 0s 772us/step - loss: 0.9049 - accuracy: 0.7440\n",
      "Epoch 427/550\n",
      "34/34 [==============================] - 0s 747us/step - loss: 0.8934 - accuracy: 0.7275\n",
      "Epoch 428/550\n",
      "34/34 [==============================] - 0s 856us/step - loss: 0.9047 - accuracy: 0.7186\n",
      "Epoch 429/550\n",
      "34/34 [==============================] - 0s 967us/step - loss: 0.8992 - accuracy: 0.7314\n",
      "Epoch 430/550\n",
      "34/34 [==============================] - 0s 771us/step - loss: 0.9386 - accuracy: 0.7345\n",
      "Epoch 431/550\n",
      "34/34 [==============================] - 0s 746us/step - loss: 0.9495 - accuracy: 0.7097\n",
      "Epoch 432/550\n",
      "34/34 [==============================] - 0s 747us/step - loss: 0.9335 - accuracy: 0.7186\n",
      "Epoch 433/550\n",
      "34/34 [==============================] - 0s 916us/step - loss: 0.9248 - accuracy: 0.7340\n",
      "Epoch 434/550\n",
      "34/34 [==============================] - 0s 824us/step - loss: 0.9130 - accuracy: 0.7315\n",
      "Epoch 435/550\n",
      "34/34 [==============================] - 0s 753us/step - loss: 0.9275 - accuracy: 0.7239\n",
      "Epoch 436/550\n",
      "34/34 [==============================] - 0s 804us/step - loss: 0.9241 - accuracy: 0.7254\n",
      "Epoch 437/550\n",
      "34/34 [==============================] - 0s 795us/step - loss: 0.9155 - accuracy: 0.7166\n",
      "Epoch 438/550\n",
      "34/34 [==============================] - 0s 864us/step - loss: 0.9306 - accuracy: 0.7307\n",
      "Epoch 439/550\n",
      "34/34 [==============================] - 0s 893us/step - loss: 0.8871 - accuracy: 0.7449\n",
      "Epoch 440/550\n",
      "34/34 [==============================] - 0s 819us/step - loss: 0.8991 - accuracy: 0.7283\n",
      "Epoch 441/550\n",
      "34/34 [==============================] - 0s 778us/step - loss: 0.9470 - accuracy: 0.7260\n",
      "Epoch 442/550\n",
      "34/34 [==============================] - 0s 781us/step - loss: 0.9125 - accuracy: 0.7251\n",
      "Epoch 443/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.8845 - accuracy: 0.7448\n",
      "Epoch 444/550\n",
      "34/34 [==============================] - 0s 956us/step - loss: 0.9174 - accuracy: 0.7344\n",
      "Epoch 445/550\n",
      "34/34 [==============================] - 0s 889us/step - loss: 0.9402 - accuracy: 0.7140\n",
      "Epoch 446/550\n",
      "34/34 [==============================] - 0s 929us/step - loss: 0.8970 - accuracy: 0.7457\n",
      "Epoch 447/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.8680 - accuracy: 0.7451\n",
      "Epoch 448/550\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.8832 - accuracy: 0.7309\n",
      "Epoch 449/550\n",
      "34/34 [==============================] - 0s 903us/step - loss: 0.8766 - accuracy: 0.7309\n",
      "Epoch 450/550\n",
      "34/34 [==============================] - 0s 854us/step - loss: 0.9376 - accuracy: 0.7120\n",
      "Epoch 451/550\n",
      "34/34 [==============================] - 0s 896us/step - loss: 0.8636 - accuracy: 0.7449\n",
      "Epoch 452/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9047 - accuracy: 0.7364\n",
      "Epoch 453/550\n",
      "34/34 [==============================] - 0s 926us/step - loss: 0.8499 - accuracy: 0.7503\n",
      "Epoch 454/550\n",
      "34/34 [==============================] - 0s 861us/step - loss: 0.8767 - accuracy: 0.7454\n",
      "Epoch 455/550\n",
      "34/34 [==============================] - 0s 883us/step - loss: 0.9115 - accuracy: 0.7214\n",
      "Epoch 456/550\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.8974 - accuracy: 0.7287\n",
      "Epoch 457/550\n",
      "34/34 [==============================] - 0s 861us/step - loss: 0.8836 - accuracy: 0.7313\n",
      "Epoch 458/550\n",
      "34/34 [==============================] - 0s 949us/step - loss: 0.8678 - accuracy: 0.7471\n",
      "Epoch 459/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.8342 - accuracy: 0.7673\n",
      "Epoch 460/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.8987 - accuracy: 0.7215\n",
      "Epoch 461/550\n",
      "34/34 [==============================] - 0s 893us/step - loss: 0.8327 - accuracy: 0.7677\n",
      "Epoch 462/550\n",
      "34/34 [==============================] - 0s 909us/step - loss: 0.8866 - accuracy: 0.7316\n",
      "Epoch 463/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.8624 - accuracy: 0.7427\n",
      "Epoch 464/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.9181 - accuracy: 0.7117\n",
      "Epoch 465/550\n",
      "34/34 [==============================] - 0s 857us/step - loss: 0.8707 - accuracy: 0.7344\n",
      "Epoch 466/550\n",
      "34/34 [==============================] - 0s 859us/step - loss: 0.8751 - accuracy: 0.7407\n",
      "Epoch 467/550\n",
      "34/34 [==============================] - 0s 916us/step - loss: 0.8676 - accuracy: 0.7521\n",
      "Epoch 468/550\n",
      "34/34 [==============================] - 0s 997us/step - loss: 0.8776 - accuracy: 0.7471\n",
      "Epoch 469/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.8277 - accuracy: 0.7638\n",
      "Epoch 470/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.8931 - accuracy: 0.7340\n",
      "Epoch 471/550\n",
      "34/34 [==============================] - 0s 947us/step - loss: 0.8745 - accuracy: 0.7538\n",
      "Epoch 472/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.8743 - accuracy: 0.7555\n",
      "Epoch 473/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.8150 - accuracy: 0.7537\n",
      "Epoch 474/550\n",
      "34/34 [==============================] - 0s 977us/step - loss: 0.8324 - accuracy: 0.7675\n",
      "Epoch 475/550\n",
      "34/34 [==============================] - 0s 923us/step - loss: 0.8461 - accuracy: 0.7419\n",
      "Epoch 476/550\n",
      "34/34 [==============================] - 0s 936us/step - loss: 0.8798 - accuracy: 0.7330\n",
      "Epoch 477/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.8607 - accuracy: 0.7394\n",
      "Epoch 478/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.8588 - accuracy: 0.7688\n",
      "Epoch 479/550\n",
      "34/34 [==============================] - 0s 929us/step - loss: 0.8559 - accuracy: 0.7447\n",
      "Epoch 480/550\n",
      "34/34 [==============================] - 0s 906us/step - loss: 0.8740 - accuracy: 0.7596\n",
      "Epoch 481/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.8507 - accuracy: 0.7404\n",
      "Epoch 482/550\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.8416 - accuracy: 0.7519\n",
      "Epoch 483/550\n",
      "34/34 [==============================] - 0s 821us/step - loss: 0.8549 - accuracy: 0.7517\n",
      "Epoch 484/550\n",
      "34/34 [==============================] - 0s 847us/step - loss: 0.8628 - accuracy: 0.7359\n",
      "Epoch 485/550\n",
      "34/34 [==============================] - 0s 804us/step - loss: 0.8530 - accuracy: 0.7458\n",
      "Epoch 486/550\n",
      "34/34 [==============================] - 0s 865us/step - loss: 0.8453 - accuracy: 0.7592\n",
      "Epoch 487/550\n",
      "34/34 [==============================] - 0s 836us/step - loss: 0.8215 - accuracy: 0.7526\n",
      "Epoch 488/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.8416 - accuracy: 0.7697\n",
      "Epoch 489/550\n",
      "34/34 [==============================] - 0s 781us/step - loss: 0.8271 - accuracy: 0.7543\n",
      "Epoch 490/550\n",
      "34/34 [==============================] - 0s 800us/step - loss: 0.9165 - accuracy: 0.7255\n",
      "Epoch 491/550\n",
      "34/34 [==============================] - 0s 841us/step - loss: 0.8293 - accuracy: 0.7271\n",
      "Epoch 492/550\n",
      "34/34 [==============================] - 0s 951us/step - loss: 0.8375 - accuracy: 0.7490\n",
      "Epoch 493/550\n",
      "34/34 [==============================] - 0s 914us/step - loss: 0.8509 - accuracy: 0.7532\n",
      "Epoch 494/550\n",
      "34/34 [==============================] - 0s 758us/step - loss: 0.8128 - accuracy: 0.7637\n",
      "Epoch 495/550\n",
      "34/34 [==============================] - 0s 829us/step - loss: 0.8514 - accuracy: 0.7525\n",
      "Epoch 496/550\n",
      "34/34 [==============================] - 0s 820us/step - loss: 0.7972 - accuracy: 0.7660\n",
      "Epoch 497/550\n",
      "34/34 [==============================] - 0s 879us/step - loss: 0.8865 - accuracy: 0.7420\n",
      "Epoch 498/550\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.7975 - accuracy: 0.7536\n",
      "Epoch 499/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.8291 - accuracy: 0.7625\n",
      "Epoch 500/550\n",
      "34/34 [==============================] - 0s 828us/step - loss: 0.8321 - accuracy: 0.7629\n",
      "Epoch 501/550\n",
      "34/34 [==============================] - 0s 791us/step - loss: 0.7976 - accuracy: 0.7777\n",
      "Epoch 502/550\n",
      "34/34 [==============================] - 0s 819us/step - loss: 0.8432 - accuracy: 0.7418\n",
      "Epoch 503/550\n",
      "34/34 [==============================] - 0s 812us/step - loss: 0.8746 - accuracy: 0.7460\n",
      "Epoch 504/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.8410 - accuracy: 0.7672\n",
      "Epoch 505/550\n",
      "34/34 [==============================] - 0s 921us/step - loss: 0.7827 - accuracy: 0.7764\n",
      "Epoch 506/550\n",
      "34/34 [==============================] - 0s 861us/step - loss: 0.8423 - accuracy: 0.7706\n",
      "Epoch 507/550\n",
      "34/34 [==============================] - 0s 808us/step - loss: 0.8182 - accuracy: 0.7690\n",
      "Epoch 508/550\n",
      "34/34 [==============================] - 0s 841us/step - loss: 0.7917 - accuracy: 0.7592\n",
      "Epoch 509/550\n",
      "34/34 [==============================] - 0s 806us/step - loss: 0.8225 - accuracy: 0.7545\n",
      "Epoch 510/550\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.8720 - accuracy: 0.7425\n",
      "Epoch 511/550\n",
      "34/34 [==============================] - 0s 817us/step - loss: 0.8098 - accuracy: 0.7567\n",
      "Epoch 512/550\n",
      "34/34 [==============================] - 0s 786us/step - loss: 0.8046 - accuracy: 0.7785\n",
      "Epoch 513/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.8123 - accuracy: 0.7562\n",
      "Epoch 514/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.7852 - accuracy: 0.7738\n",
      "Epoch 515/550\n",
      "34/34 [==============================] - 0s 868us/step - loss: 0.7982 - accuracy: 0.7562\n",
      "Epoch 516/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.7539 - accuracy: 0.7913\n",
      "Epoch 517/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.8352 - accuracy: 0.7701\n",
      "Epoch 518/550\n",
      "34/34 [==============================] - 0s 966us/step - loss: 0.8472 - accuracy: 0.7432\n",
      "Epoch 519/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.8130 - accuracy: 0.7447\n",
      "Epoch 520/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.8393 - accuracy: 0.7452\n",
      "Epoch 521/550\n",
      "34/34 [==============================] - 0s 809us/step - loss: 0.7922 - accuracy: 0.7741\n",
      "Epoch 522/550\n",
      "34/34 [==============================] - 0s 846us/step - loss: 0.8032 - accuracy: 0.7621\n",
      "Epoch 523/550\n",
      "34/34 [==============================] - 0s 790us/step - loss: 0.7922 - accuracy: 0.7645\n",
      "Epoch 524/550\n",
      "34/34 [==============================] - 0s 828us/step - loss: 0.8298 - accuracy: 0.7609\n",
      "Epoch 525/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.8458 - accuracy: 0.7581\n",
      "Epoch 526/550\n",
      "34/34 [==============================] - 0s 928us/step - loss: 0.7619 - accuracy: 0.7741\n",
      "Epoch 527/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.8241 - accuracy: 0.7682\n",
      "Epoch 528/550\n",
      "34/34 [==============================] - 0s 873us/step - loss: 0.8371 - accuracy: 0.7563\n",
      "Epoch 529/550\n",
      "34/34 [==============================] - 0s 920us/step - loss: 0.7677 - accuracy: 0.7736\n",
      "Epoch 530/550\n",
      "34/34 [==============================] - 0s 850us/step - loss: 0.7945 - accuracy: 0.7583\n",
      "Epoch 531/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.7720 - accuracy: 0.7893\n",
      "Epoch 532/550\n",
      "34/34 [==============================] - 0s 911us/step - loss: 0.7816 - accuracy: 0.7743\n",
      "Epoch 533/550\n",
      "34/34 [==============================] - 0s 866us/step - loss: 0.8166 - accuracy: 0.7569\n",
      "Epoch 534/550\n",
      "34/34 [==============================] - 0s 845us/step - loss: 0.7688 - accuracy: 0.7738\n",
      "Epoch 535/550\n",
      "34/34 [==============================] - 0s 789us/step - loss: 0.7786 - accuracy: 0.7737\n",
      "Epoch 536/550\n",
      "34/34 [==============================] - 0s 857us/step - loss: 0.8514 - accuracy: 0.7645\n",
      "Epoch 537/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.7817 - accuracy: 0.7818\n",
      "Epoch 538/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.7527 - accuracy: 0.7905\n",
      "Epoch 539/550\n",
      "34/34 [==============================] - 0s 946us/step - loss: 0.7791 - accuracy: 0.7708\n",
      "Epoch 540/550\n",
      "34/34 [==============================] - 0s 861us/step - loss: 0.7505 - accuracy: 0.7964\n",
      "Epoch 541/550\n",
      "34/34 [==============================] - 0s 908us/step - loss: 0.7547 - accuracy: 0.7796\n",
      "Epoch 542/550\n",
      "34/34 [==============================] - 0s 801us/step - loss: 0.7933 - accuracy: 0.7799\n",
      "Epoch 543/550\n",
      "34/34 [==============================] - 0s 795us/step - loss: 0.7558 - accuracy: 0.7897\n",
      "Epoch 544/550\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.8042 - accuracy: 0.7811\n",
      "Epoch 545/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.7417 - accuracy: 0.7757\n",
      "Epoch 546/550\n",
      "34/34 [==============================] - 0s 892us/step - loss: 0.7477 - accuracy: 0.7899\n",
      "Epoch 547/550\n",
      "34/34 [==============================] - 0s 774us/step - loss: 0.7991 - accuracy: 0.7739\n",
      "Epoch 548/550\n",
      "34/34 [==============================] - 0s 815us/step - loss: 0.7699 - accuracy: 0.7641\n",
      "Epoch 549/550\n",
      "34/34 [==============================] - 0s 918us/step - loss: 0.7909 - accuracy: 0.7720\n",
      "Epoch 550/550\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.7844 - accuracy: 0.7738\n"
     ]
    }
   ],
   "source": [
    "# 对于具有10个类的单输入模型（多分类分类）\n",
    "model = Sequential()\n",
    "model.add(Dense(20, activation='relu', input_dim=100))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 生成虚拟数据\n",
    "import numpy as np\n",
    "data = np.random.random((1000,100))\n",
    "labels = np.random.randint(10, size=(1000,1))\n",
    "print(data)\n",
    "#将标签转换为十维的one-hot编码\n",
    "one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)\n",
    "print('data:', data.shape, '\\nlabels:', labels.shape)\n",
    "print(model.summary())\n",
    "# 训练数据，以32个样本为一个batch进行迭代\n",
    "history = model.fit(data, one_hot_labels, epochs=550, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "550"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "len(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.3313 - accuracy: 0.0976\n",
      "Epoch 2/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.3136 - accuracy: 0.0992\n",
      "Epoch 3/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2970 - accuracy: 0.1231\n",
      "Epoch 4/300\n",
      "20/20 [==============================] - 0s 866us/step - loss: 2.3040 - accuracy: 0.1180\n",
      "Epoch 5/300\n",
      "20/20 [==============================] - 0s 965us/step - loss: 2.3017 - accuracy: 0.1252\n",
      "Epoch 6/300\n",
      "20/20 [==============================] - 0s 927us/step - loss: 2.2939 - accuracy: 0.1078\n",
      "Epoch 7/300\n",
      "20/20 [==============================] - 0s 842us/step - loss: 2.2963 - accuracy: 0.1205\n",
      "Epoch 8/300\n",
      "20/20 [==============================] - 0s 965us/step - loss: 2.2992 - accuracy: 0.1215\n",
      "Epoch 9/300\n",
      "20/20 [==============================] - 0s 839us/step - loss: 2.2887 - accuracy: 0.1488\n",
      "Epoch 10/300\n",
      "20/20 [==============================] - 0s 888us/step - loss: 2.2846 - accuracy: 0.1323\n",
      "Epoch 11/300\n",
      "20/20 [==============================] - 0s 982us/step - loss: 2.2886 - accuracy: 0.1325\n",
      "Epoch 12/300\n",
      "20/20 [==============================] - 0s 915us/step - loss: 2.2796 - accuracy: 0.1520\n",
      "Epoch 13/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2876 - accuracy: 0.1305\n",
      "Epoch 14/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2791 - accuracy: 0.1598\n",
      "Epoch 15/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2851 - accuracy: 0.1436\n",
      "Epoch 16/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2775 - accuracy: 0.1669\n",
      "Epoch 17/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2793 - accuracy: 0.1360\n",
      "Epoch 18/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2745 - accuracy: 0.1364\n",
      "Epoch 19/300\n",
      "20/20 [==============================] - 0s 978us/step - loss: 2.2836 - accuracy: 0.1428\n",
      "Epoch 20/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2747 - accuracy: 0.1617\n",
      "Epoch 21/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2877 - accuracy: 0.1432\n",
      "Epoch 22/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2776 - accuracy: 0.1450\n",
      "Epoch 23/300\n",
      "20/20 [==============================] - 0s 875us/step - loss: 2.2756 - accuracy: 0.1460\n",
      "Epoch 24/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2699 - accuracy: 0.1395\n",
      "Epoch 25/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2590 - accuracy: 0.1612\n",
      "Epoch 26/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2686 - accuracy: 0.1397\n",
      "Epoch 27/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2669 - accuracy: 0.1658\n",
      "Epoch 28/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2626 - accuracy: 0.1697\n",
      "Epoch 29/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2739 - accuracy: 0.1748\n",
      "Epoch 30/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2798 - accuracy: 0.1532\n",
      "Epoch 31/300\n",
      "20/20 [==============================] - 0s 949us/step - loss: 2.2554 - accuracy: 0.1658\n",
      "Epoch 32/300\n",
      "20/20 [==============================] - 0s 950us/step - loss: 2.2636 - accuracy: 0.1812\n",
      "Epoch 33/300\n",
      "20/20 [==============================] - 0s 977us/step - loss: 2.2626 - accuracy: 0.1614\n",
      "Epoch 34/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2598 - accuracy: 0.1467\n",
      "Epoch 35/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2509 - accuracy: 0.1697\n",
      "Epoch 36/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2519 - accuracy: 0.1606\n",
      "Epoch 37/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2667 - accuracy: 0.1439\n",
      "Epoch 38/300\n",
      "20/20 [==============================] - 0s 984us/step - loss: 2.2638 - accuracy: 0.1563\n",
      "Epoch 39/300\n",
      "20/20 [==============================] - 0s 890us/step - loss: 2.2498 - accuracy: 0.1503\n",
      "Epoch 40/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2521 - accuracy: 0.1574\n",
      "Epoch 41/300\n",
      "20/20 [==============================] - 0s 977us/step - loss: 2.2473 - accuracy: 0.1754\n",
      "Epoch 42/300\n",
      "20/20 [==============================] - 0s 872us/step - loss: 2.2443 - accuracy: 0.1564\n",
      "Epoch 43/300\n",
      "20/20 [==============================] - 0s 954us/step - loss: 2.2479 - accuracy: 0.1510\n",
      "Epoch 44/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2511 - accuracy: 0.1554\n",
      "Epoch 45/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2346 - accuracy: 0.1804\n",
      "Epoch 46/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2482 - accuracy: 0.1437\n",
      "Epoch 47/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2443 - accuracy: 0.1613\n",
      "Epoch 48/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2313 - accuracy: 0.1887\n",
      "Epoch 49/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2347 - accuracy: 0.1721\n",
      "Epoch 50/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2418 - accuracy: 0.1655\n",
      "Epoch 51/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2329 - accuracy: 0.1965\n",
      "Epoch 52/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2468 - accuracy: 0.1757\n",
      "Epoch 53/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2306 - accuracy: 0.1774\n",
      "Epoch 54/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2326 - accuracy: 0.1826\n",
      "Epoch 55/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2403 - accuracy: 0.1965\n",
      "Epoch 56/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2208 - accuracy: 0.1984\n",
      "Epoch 57/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2137 - accuracy: 0.1966\n",
      "Epoch 58/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2119 - accuracy: 0.2098\n",
      "Epoch 59/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2129 - accuracy: 0.1872\n",
      "Epoch 60/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2151 - accuracy: 0.2020\n",
      "Epoch 61/300\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 2.2218 - accuracy: 0.2046\n",
      "Epoch 62/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2387 - accuracy: 0.1618\n",
      "Epoch 63/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2030 - accuracy: 0.1960\n",
      "Epoch 64/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2082 - accuracy: 0.1897\n",
      "Epoch 65/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1931 - accuracy: 0.2116\n",
      "Epoch 66/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1770 - accuracy: 0.2329\n",
      "Epoch 67/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1860 - accuracy: 0.2040\n",
      "Epoch 68/300\n",
      "20/20 [==============================] - 0s 917us/step - loss: 2.1940 - accuracy: 0.1760\n",
      "Epoch 69/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2227 - accuracy: 0.1856\n",
      "Epoch 70/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1766 - accuracy: 0.2022\n",
      "Epoch 71/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1995 - accuracy: 0.1737\n",
      "Epoch 72/300\n",
      "20/20 [==============================] - 0s 901us/step - loss: 2.1745 - accuracy: 0.2273\n",
      "Epoch 73/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1690 - accuracy: 0.2112\n",
      "Epoch 74/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1782 - accuracy: 0.2223\n",
      "Epoch 75/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.2132 - accuracy: 0.1868\n",
      "Epoch 76/300\n",
      "20/20 [==============================] - 0s 887us/step - loss: 2.1827 - accuracy: 0.2167\n",
      "Epoch 77/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1923 - accuracy: 0.1941\n",
      "Epoch 78/300\n",
      "20/20 [==============================] - 0s 969us/step - loss: 2.1955 - accuracy: 0.1931\n",
      "Epoch 79/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1725 - accuracy: 0.2223\n",
      "Epoch 80/300\n",
      "20/20 [==============================] - 0s 917us/step - loss: 2.1895 - accuracy: 0.1962\n",
      "Epoch 81/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1819 - accuracy: 0.2051\n",
      "Epoch 82/300\n",
      "20/20 [==============================] - 0s 942us/step - loss: 2.1600 - accuracy: 0.2035\n",
      "Epoch 83/300\n",
      "20/20 [==============================] - 0s 975us/step - loss: 2.1497 - accuracy: 0.2230\n",
      "Epoch 84/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1579 - accuracy: 0.2169\n",
      "Epoch 85/300\n",
      "20/20 [==============================] - 0s 937us/step - loss: 2.1517 - accuracy: 0.2221\n",
      "Epoch 86/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1300 - accuracy: 0.2398\n",
      "Epoch 87/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1767 - accuracy: 0.2069\n",
      "Epoch 88/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1408 - accuracy: 0.2330\n",
      "Epoch 89/300\n",
      "20/20 [==============================] - 0s 819us/step - loss: 2.1736 - accuracy: 0.1993\n",
      "Epoch 90/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1570 - accuracy: 0.2217\n",
      "Epoch 91/300\n",
      "20/20 [==============================] - 0s 873us/step - loss: 2.1369 - accuracy: 0.2317\n",
      "Epoch 92/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1618 - accuracy: 0.2050\n",
      "Epoch 93/300\n",
      "20/20 [==============================] - 0s 969us/step - loss: 2.1654 - accuracy: 0.2027\n",
      "Epoch 94/300\n",
      "20/20 [==============================] - 0s 987us/step - loss: 2.1303 - accuracy: 0.2276\n",
      "Epoch 95/300\n",
      "20/20 [==============================] - 0s 937us/step - loss: 2.1374 - accuracy: 0.2221\n",
      "Epoch 96/300\n",
      "20/20 [==============================] - 0s 930us/step - loss: 2.1368 - accuracy: 0.2187\n",
      "Epoch 97/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1417 - accuracy: 0.2515\n",
      "Epoch 98/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1410 - accuracy: 0.2286\n",
      "Epoch 99/300\n",
      "20/20 [==============================] - 0s 989us/step - loss: 2.1531 - accuracy: 0.2381\n",
      "Epoch 100/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1467 - accuracy: 0.2367\n",
      "Epoch 101/300\n",
      "20/20 [==============================] - 0s 931us/step - loss: 2.1319 - accuracy: 0.2362\n",
      "Epoch 102/300\n",
      "20/20 [==============================] - 0s 984us/step - loss: 2.1248 - accuracy: 0.2194\n",
      "Epoch 103/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1414 - accuracy: 0.2377\n",
      "Epoch 104/300\n",
      "20/20 [==============================] - 0s 896us/step - loss: 2.1296 - accuracy: 0.2440\n",
      "Epoch 105/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1423 - accuracy: 0.2357\n",
      "Epoch 106/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1000 - accuracy: 0.2485\n",
      "Epoch 107/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1278 - accuracy: 0.2361\n",
      "Epoch 108/300\n",
      "20/20 [==============================] - 0s 919us/step - loss: 2.1336 - accuracy: 0.2155\n",
      "Epoch 109/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1260 - accuracy: 0.2440\n",
      "Epoch 110/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1210 - accuracy: 0.2464\n",
      "Epoch 111/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1136 - accuracy: 0.2395\n",
      "Epoch 112/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1108 - accuracy: 0.2432\n",
      "Epoch 113/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1324 - accuracy: 0.2233\n",
      "Epoch 114/300\n",
      "20/20 [==============================] - 0s 841us/step - loss: 2.0950 - accuracy: 0.2685\n",
      "Epoch 115/300\n",
      "20/20 [==============================] - 0s 991us/step - loss: 2.0904 - accuracy: 0.2343\n",
      "Epoch 116/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.0992 - accuracy: 0.2332\n",
      "Epoch 117/300\n",
      "20/20 [==============================] - 0s 948us/step - loss: 2.0846 - accuracy: 0.2525\n",
      "Epoch 118/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.1014 - accuracy: 0.2401\n",
      "Epoch 119/300\n",
      "20/20 [==============================] - 0s 813us/step - loss: 2.0965 - accuracy: 0.2625\n",
      "Epoch 120/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.0768 - accuracy: 0.2694\n",
      "Epoch 121/300\n",
      "20/20 [==============================] - 0s 954us/step - loss: 2.0662 - accuracy: 0.2613\n",
      "Epoch 122/300\n",
      "20/20 [==============================] - 0s 900us/step - loss: 2.0620 - accuracy: 0.2868\n",
      "Epoch 123/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.0723 - accuracy: 0.2623\n",
      "Epoch 124/300\n",
      "20/20 [==============================] - 0s 884us/step - loss: 2.1102 - accuracy: 0.2293\n",
      "Epoch 125/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.0928 - accuracy: 0.2470\n",
      "Epoch 126/300\n",
      "20/20 [==============================] - 0s 871us/step - loss: 2.0538 - accuracy: 0.2749\n",
      "Epoch 127/300\n",
      "20/20 [==============================] - 0s 988us/step - loss: 2.0403 - accuracy: 0.2669\n",
      "Epoch 128/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.0562 - accuracy: 0.2587\n",
      "Epoch 129/300\n",
      "20/20 [==============================] - 0s 988us/step - loss: 2.0460 - accuracy: 0.2730\n",
      "Epoch 130/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.0594 - accuracy: 0.2623\n",
      "Epoch 131/300\n",
      "20/20 [==============================] - 0s 989us/step - loss: 2.0669 - accuracy: 0.2714\n",
      "Epoch 132/300\n",
      "20/20 [==============================] - 0s 788us/step - loss: 2.0585 - accuracy: 0.2497\n",
      "Epoch 133/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.0564 - accuracy: 0.2734\n",
      "Epoch 134/300\n",
      "20/20 [==============================] - 0s 854us/step - loss: 2.0458 - accuracy: 0.2977\n",
      "Epoch 135/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.0592 - accuracy: 0.2594\n",
      "Epoch 136/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.0599 - accuracy: 0.2680\n",
      "Epoch 137/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.0728 - accuracy: 0.2596\n",
      "Epoch 138/300\n",
      "20/20 [==============================] - 0s 849us/step - loss: 2.0661 - accuracy: 0.2632\n",
      "Epoch 139/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.0193 - accuracy: 0.2652\n",
      "Epoch 140/300\n",
      "20/20 [==============================] - 0s 955us/step - loss: 2.0468 - accuracy: 0.2822\n",
      "Epoch 141/300\n",
      "20/20 [==============================] - 0s 974us/step - loss: 2.0491 - accuracy: 0.2643\n",
      "Epoch 142/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.0170 - accuracy: 0.2685\n",
      "Epoch 143/300\n",
      "20/20 [==============================] - 0s 846us/step - loss: 2.0203 - accuracy: 0.2658\n",
      "Epoch 144/300\n",
      "20/20 [==============================] - 0s 958us/step - loss: 2.0438 - accuracy: 0.2638\n",
      "Epoch 145/300\n",
      "20/20 [==============================] - 0s 987us/step - loss: 1.9664 - accuracy: 0.3249\n",
      "Epoch 146/300\n",
      "20/20 [==============================] - 0s 978us/step - loss: 1.9993 - accuracy: 0.2889\n",
      "Epoch 147/300\n",
      "20/20 [==============================] - 0s 893us/step - loss: 1.9953 - accuracy: 0.3151\n",
      "Epoch 148/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.0081 - accuracy: 0.2860\n",
      "Epoch 149/300\n",
      "20/20 [==============================] - 0s 986us/step - loss: 1.9806 - accuracy: 0.2814\n",
      "Epoch 150/300\n",
      "20/20 [==============================] - 0s 874us/step - loss: 1.9796 - accuracy: 0.3198\n",
      "Epoch 151/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.9898 - accuracy: 0.2945\n",
      "Epoch 152/300\n",
      "20/20 [==============================] - 0s 867us/step - loss: 1.9736 - accuracy: 0.3004\n",
      "Epoch 153/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.9958 - accuracy: 0.2730\n",
      "Epoch 154/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.9628 - accuracy: 0.3093\n",
      "Epoch 155/300\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.9775 - accuracy: 0.3289\n",
      "Epoch 156/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.9889 - accuracy: 0.2978\n",
      "Epoch 157/300\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.9637 - accuracy: 0.2858\n",
      "Epoch 158/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.9655 - accuracy: 0.3034\n",
      "Epoch 159/300\n",
      "20/20 [==============================] - 0s 874us/step - loss: 1.9416 - accuracy: 0.3229\n",
      "Epoch 160/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 2.0061 - accuracy: 0.2761\n",
      "Epoch 161/300\n",
      "20/20 [==============================] - 0s 949us/step - loss: 1.9658 - accuracy: 0.3042\n",
      "Epoch 162/300\n",
      "20/20 [==============================] - 0s 871us/step - loss: 1.9661 - accuracy: 0.3019\n",
      "Epoch 163/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.9814 - accuracy: 0.3014\n",
      "Epoch 164/300\n",
      "20/20 [==============================] - 0s 869us/step - loss: 1.9676 - accuracy: 0.2945\n",
      "Epoch 165/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.9574 - accuracy: 0.3040\n",
      "Epoch 166/300\n",
      "20/20 [==============================] - 0s 948us/step - loss: 1.9606 - accuracy: 0.3019\n",
      "Epoch 167/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.9622 - accuracy: 0.2941\n",
      "Epoch 168/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.9519 - accuracy: 0.3267\n",
      "Epoch 169/300\n",
      "20/20 [==============================] - 0s 876us/step - loss: 1.9662 - accuracy: 0.2901\n",
      "Epoch 170/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.9596 - accuracy: 0.3151\n",
      "Epoch 171/300\n",
      "20/20 [==============================] - 0s 986us/step - loss: 1.9308 - accuracy: 0.2987\n",
      "Epoch 172/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.9302 - accuracy: 0.3045\n",
      "Epoch 173/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.9448 - accuracy: 0.2839\n",
      "Epoch 174/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.9160 - accuracy: 0.3035\n",
      "Epoch 175/300\n",
      "20/20 [==============================] - 0s 868us/step - loss: 1.9018 - accuracy: 0.3184\n",
      "Epoch 176/300\n",
      "20/20 [==============================] - 0s 971us/step - loss: 1.8808 - accuracy: 0.3263\n",
      "Epoch 177/300\n",
      "20/20 [==============================] - 0s 944us/step - loss: 1.9209 - accuracy: 0.3134\n",
      "Epoch 178/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.9621 - accuracy: 0.3052\n",
      "Epoch 179/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.8625 - accuracy: 0.3547\n",
      "Epoch 180/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.9025 - accuracy: 0.3338\n",
      "Epoch 181/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.9206 - accuracy: 0.3231\n",
      "Epoch 182/300\n",
      "20/20 [==============================] - 0s 965us/step - loss: 1.9669 - accuracy: 0.2973\n",
      "Epoch 183/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.8600 - accuracy: 0.3694\n",
      "Epoch 184/300\n",
      "20/20 [==============================] - 0s 949us/step - loss: 1.9279 - accuracy: 0.3101\n",
      "Epoch 185/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.9046 - accuracy: 0.3220\n",
      "Epoch 186/300\n",
      "20/20 [==============================] - 0s 826us/step - loss: 1.8385 - accuracy: 0.3614\n",
      "Epoch 187/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.8896 - accuracy: 0.3259\n",
      "Epoch 188/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.8509 - accuracy: 0.3387\n",
      "Epoch 189/300\n",
      "20/20 [==============================] - 0s 863us/step - loss: 1.8697 - accuracy: 0.3686\n",
      "Epoch 190/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.8751 - accuracy: 0.3454\n",
      "Epoch 191/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.8510 - accuracy: 0.3619\n",
      "Epoch 192/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.8799 - accuracy: 0.3297\n",
      "Epoch 193/300\n",
      "20/20 [==============================] - 0s 863us/step - loss: 1.8464 - accuracy: 0.3467\n",
      "Epoch 194/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.8758 - accuracy: 0.3621\n",
      "Epoch 195/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.8233 - accuracy: 0.3878\n",
      "Epoch 196/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.8822 - accuracy: 0.3148\n",
      "Epoch 197/300\n",
      "20/20 [==============================] - 0s 975us/step - loss: 1.8079 - accuracy: 0.3670\n",
      "Epoch 198/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.8310 - accuracy: 0.3442\n",
      "Epoch 199/300\n",
      "20/20 [==============================] - 0s 943us/step - loss: 1.8198 - accuracy: 0.3681\n",
      "Epoch 200/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.8423 - accuracy: 0.3636\n",
      "Epoch 201/300\n",
      "20/20 [==============================] - 0s 976us/step - loss: 1.8170 - accuracy: 0.3549\n",
      "Epoch 202/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.8159 - accuracy: 0.3422\n",
      "Epoch 203/300\n",
      "20/20 [==============================] - 0s 975us/step - loss: 1.8383 - accuracy: 0.3622\n",
      "Epoch 204/300\n",
      "20/20 [==============================] - 0s 877us/step - loss: 1.8629 - accuracy: 0.3268\n",
      "Epoch 205/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.8096 - accuracy: 0.3512\n",
      "Epoch 206/300\n",
      "20/20 [==============================] - 0s 876us/step - loss: 1.7936 - accuracy: 0.4099\n",
      "Epoch 207/300\n",
      "20/20 [==============================] - 0s 923us/step - loss: 1.8130 - accuracy: 0.3568\n",
      "Epoch 208/300\n",
      "20/20 [==============================] - 0s 992us/step - loss: 1.8242 - accuracy: 0.3966\n",
      "Epoch 209/300\n",
      "20/20 [==============================] - 0s 846us/step - loss: 1.8099 - accuracy: 0.3388\n",
      "Epoch 210/300\n",
      "20/20 [==============================] - 0s 952us/step - loss: 1.8009 - accuracy: 0.3484\n",
      "Epoch 211/300\n",
      "20/20 [==============================] - 0s 846us/step - loss: 1.8529 - accuracy: 0.3261\n",
      "Epoch 212/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.7741 - accuracy: 0.3907\n",
      "Epoch 213/300\n",
      "20/20 [==============================] - 0s 971us/step - loss: 1.7589 - accuracy: 0.3670\n",
      "Epoch 214/300\n",
      "20/20 [==============================] - 0s 922us/step - loss: 1.7991 - accuracy: 0.3794\n",
      "Epoch 215/300\n",
      "20/20 [==============================] - 0s 914us/step - loss: 1.7966 - accuracy: 0.3733\n",
      "Epoch 216/300\n",
      "20/20 [==============================] - 0s 860us/step - loss: 1.8242 - accuracy: 0.3445\n",
      "Epoch 217/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.7724 - accuracy: 0.3611\n",
      "Epoch 218/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.7711 - accuracy: 0.3859\n",
      "Epoch 219/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.8091 - accuracy: 0.3436\n",
      "Epoch 220/300\n",
      "20/20 [==============================] - 0s 900us/step - loss: 1.7721 - accuracy: 0.3422\n",
      "Epoch 221/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.7908 - accuracy: 0.3728\n",
      "Epoch 222/300\n",
      "20/20 [==============================] - 0s 957us/step - loss: 1.7983 - accuracy: 0.3309\n",
      "Epoch 223/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.7697 - accuracy: 0.3580\n",
      "Epoch 224/300\n",
      "20/20 [==============================] - 0s 860us/step - loss: 1.7567 - accuracy: 0.3787\n",
      "Epoch 225/300\n",
      "20/20 [==============================] - 0s 993us/step - loss: 1.7456 - accuracy: 0.3948\n",
      "Epoch 226/300\n",
      "20/20 [==============================] - 0s 957us/step - loss: 1.7696 - accuracy: 0.3724\n",
      "Epoch 227/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.7441 - accuracy: 0.3928\n",
      "Epoch 228/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.7628 - accuracy: 0.3873\n",
      "Epoch 229/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.7582 - accuracy: 0.4050\n",
      "Epoch 230/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.7230 - accuracy: 0.3809\n",
      "Epoch 231/300\n",
      "20/20 [==============================] - 0s 889us/step - loss: 1.7537 - accuracy: 0.3806\n",
      "Epoch 232/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.7756 - accuracy: 0.3902\n",
      "Epoch 233/300\n",
      "20/20 [==============================] - 0s 939us/step - loss: 1.7415 - accuracy: 0.4128\n",
      "Epoch 234/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.7666 - accuracy: 0.3776\n",
      "Epoch 235/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.8036 - accuracy: 0.3820\n",
      "Epoch 236/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.7008 - accuracy: 0.4108\n",
      "Epoch 237/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.7495 - accuracy: 0.4182\n",
      "Epoch 238/300\n",
      "20/20 [==============================] - 0s 849us/step - loss: 1.6758 - accuracy: 0.3933\n",
      "Epoch 239/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.7505 - accuracy: 0.3949\n",
      "Epoch 240/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.6789 - accuracy: 0.4078\n",
      "Epoch 241/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.6880 - accuracy: 0.4288\n",
      "Epoch 242/300\n",
      "20/20 [==============================] - 0s 985us/step - loss: 1.6992 - accuracy: 0.3818\n",
      "Epoch 243/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.7198 - accuracy: 0.4093\n",
      "Epoch 244/300\n",
      "20/20 [==============================] - 0s 855us/step - loss: 1.7318 - accuracy: 0.3944\n",
      "Epoch 245/300\n",
      "20/20 [==============================] - 0s 944us/step - loss: 1.6938 - accuracy: 0.3922\n",
      "Epoch 246/300\n",
      "20/20 [==============================] - 0s 967us/step - loss: 1.6804 - accuracy: 0.4171\n",
      "Epoch 247/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.6906 - accuracy: 0.3873\n",
      "Epoch 248/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.7525 - accuracy: 0.3742\n",
      "Epoch 249/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.6317 - accuracy: 0.4092\n",
      "Epoch 250/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.6883 - accuracy: 0.3752\n",
      "Epoch 251/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.6767 - accuracy: 0.4032\n",
      "Epoch 252/300\n",
      "20/20 [==============================] - 0s 836us/step - loss: 1.6930 - accuracy: 0.4277\n",
      "Epoch 253/300\n",
      "20/20 [==============================] - 0s 926us/step - loss: 1.6576 - accuracy: 0.4436\n",
      "Epoch 254/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.6803 - accuracy: 0.4156\n",
      "Epoch 255/300\n",
      "20/20 [==============================] - 0s 992us/step - loss: 1.6822 - accuracy: 0.4066\n",
      "Epoch 256/300\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.6725 - accuracy: 0.4036\n",
      "Epoch 257/300\n",
      "20/20 [==============================] - 0s 908us/step - loss: 1.6677 - accuracy: 0.4042\n",
      "Epoch 258/300\n",
      "20/20 [==============================] - 0s 906us/step - loss: 1.6646 - accuracy: 0.4178\n",
      "Epoch 259/300\n",
      "20/20 [==============================] - 0s 939us/step - loss: 1.6719 - accuracy: 0.3912\n",
      "Epoch 260/300\n",
      "20/20 [==============================] - 0s 914us/step - loss: 1.6402 - accuracy: 0.4266\n",
      "Epoch 261/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.6765 - accuracy: 0.4179\n",
      "Epoch 262/300\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.6759 - accuracy: 0.4182\n",
      "Epoch 263/300\n",
      "20/20 [==============================] - 0s 955us/step - loss: 1.6701 - accuracy: 0.4048\n",
      "Epoch 264/300\n",
      "20/20 [==============================] - 0s 967us/step - loss: 1.6368 - accuracy: 0.4156\n",
      "Epoch 265/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.6282 - accuracy: 0.4239\n",
      "Epoch 266/300\n",
      "20/20 [==============================] - 0s 860us/step - loss: 1.6145 - accuracy: 0.4379\n",
      "Epoch 267/300\n",
      "20/20 [==============================] - 0s 896us/step - loss: 1.6557 - accuracy: 0.4107\n",
      "Epoch 268/300\n",
      "20/20 [==============================] - 0s 927us/step - loss: 1.6541 - accuracy: 0.4146\n",
      "Epoch 269/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.6341 - accuracy: 0.4197\n",
      "Epoch 270/300\n",
      "20/20 [==============================] - 0s 853us/step - loss: 1.6450 - accuracy: 0.4080\n",
      "Epoch 271/300\n",
      "20/20 [==============================] - 0s 883us/step - loss: 1.5952 - accuracy: 0.4449\n",
      "Epoch 272/300\n",
      "20/20 [==============================] - 0s 876us/step - loss: 1.6168 - accuracy: 0.4560\n",
      "Epoch 273/300\n",
      "20/20 [==============================] - 0s 869us/step - loss: 1.6196 - accuracy: 0.4350\n",
      "Epoch 274/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.6788 - accuracy: 0.4075\n",
      "Epoch 275/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.6715 - accuracy: 0.4173\n",
      "Epoch 276/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.5828 - accuracy: 0.4469\n",
      "Epoch 277/300\n",
      "20/20 [==============================] - 0s 997us/step - loss: 1.6341 - accuracy: 0.4346\n",
      "Epoch 278/300\n",
      "20/20 [==============================] - 0s 941us/step - loss: 1.6483 - accuracy: 0.4151\n",
      "Epoch 279/300\n",
      "20/20 [==============================] - 0s 894us/step - loss: 1.6285 - accuracy: 0.4191\n",
      "Epoch 280/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.6328 - accuracy: 0.3992\n",
      "Epoch 281/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.6178 - accuracy: 0.4320\n",
      "Epoch 282/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.6419 - accuracy: 0.4225\n",
      "Epoch 283/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.5850 - accuracy: 0.4490\n",
      "Epoch 284/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.5768 - accuracy: 0.4412\n",
      "Epoch 285/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.5865 - accuracy: 0.4329\n",
      "Epoch 286/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.5606 - accuracy: 0.4626\n",
      "Epoch 287/300\n",
      "20/20 [==============================] - 0s 957us/step - loss: 1.6476 - accuracy: 0.4115\n",
      "Epoch 288/300\n",
      "20/20 [==============================] - 0s 894us/step - loss: 1.5914 - accuracy: 0.4532\n",
      "Epoch 289/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.5218 - accuracy: 0.4680\n",
      "Epoch 290/300\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.6050 - accuracy: 0.4493\n",
      "Epoch 291/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.5685 - accuracy: 0.4525\n",
      "Epoch 292/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.5693 - accuracy: 0.4523\n",
      "Epoch 293/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.5785 - accuracy: 0.4471\n",
      "Epoch 294/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.6135 - accuracy: 0.4604\n",
      "Epoch 295/300\n",
      "20/20 [==============================] - 0s 947us/step - loss: 1.5564 - accuracy: 0.4300\n",
      "Epoch 296/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.5669 - accuracy: 0.4442\n",
      "Epoch 297/300\n",
      "20/20 [==============================] - 0s 904us/step - loss: 1.6022 - accuracy: 0.4216\n",
      "Epoch 298/300\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.5707 - accuracy: 0.4654\n",
      "Epoch 299/300\n",
      "20/20 [==============================] - 0s 971us/step - loss: 1.5265 - accuracy: 0.4577\n",
      "Epoch 300/300\n",
      "20/20 [==============================] - 0s 889us/step - loss: 1.5649 - accuracy: 0.4353\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 2.8852 - accuracy: 0.1000\n",
      "[2.8852198123931885, 0.10000000149011612]\n"
     ]
    }
   ],
   "source": [
    "# 生成虚拟数据\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000,1)), num_classes=10)\n",
    "x_test = np.random.random((100,20))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim = 20))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=300, batch_size=50)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, batch_size=100)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7194 - accuracy: 0.4811\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7123 - accuracy: 0.5138\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6991 - accuracy: 0.5226\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.5400\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6980 - accuracy: 0.5230\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6985 - accuracy: 0.5106\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5232\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6978 - accuracy: 0.5007\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5060\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6974 - accuracy: 0.5083\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6926 - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# 基于多层感知器的二分类\n",
    "\n",
    "# 生成虚拟数据\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = np.random.randint(2, size=(1000, 1))\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = np.random.randint(2, size=(100, 1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=20, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=10,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于LSTM的序列分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1000, 20)\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 2s 13ms/step - loss: 0.6992 - accuracy: 0.4923\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6956 - accuracy: 0.5099\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.6959 - accuracy: 0.5275\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6977 - accuracy: 0.4871\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6932 - accuracy: 0.5391\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6946 - accuracy: 0.4999\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6933 - accuracy: 0.5343\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6963 - accuracy: 0.4437\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6939 - accuracy: 0.5027\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6945 - accuracy: 0.4965\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7088 - accuracy: 0.4500\n",
      "[0.7087590098381042, 0.44999998807907104]\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "max_features = 1024\n",
    "print(x_train.shape)\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, output_dim=256))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#print(model.layers[0].get_weights())\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=16, epochs=10)\n",
    "score = model.evaluate(x_test, y_test, batch_size=16)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_6\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 7, 2)              8         \n=================================================================\nTotal params: 8\nTrainable params: 8\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Embedding(4,2,input_length=7))\n",
    "\n",
    "model1.compile('rmsprop', 'mse')\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1 2 3 1 1 1 1]\n [1 2 3 3 3 3 3]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[ 0.01593133, -0.00334835],\n",
       "        [-0.02737178,  0.03142699],\n",
       "        [-0.03236508,  0.02008871],\n",
       "        [ 0.01593133, -0.00334835],\n",
       "        [ 0.01593133, -0.00334835],\n",
       "        [ 0.01593133, -0.00334835],\n",
       "        [ 0.01593133, -0.00334835]],\n",
       "\n",
       "       [[ 0.01593133, -0.00334835],\n",
       "        [-0.02737178,  0.03142699],\n",
       "        [-0.03236508,  0.02008871],\n",
       "        [-0.03236508,  0.02008871],\n",
       "        [-0.03236508,  0.02008871],\n",
       "        [-0.03236508,  0.02008871],\n",
       "        [-0.03236508,  0.02008871]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "data1 = np.array([[1,2,3,1,1,1,1], [1,2,3,3,3,3,3]])\n",
    "print(data1)\n",
    "model1.predict(data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于栈式LSTM的序列分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 6s 118ms/step - loss: 11.9171 - accuracy: 0.1029 - val_loss: 13.9478 - val_accuracy: 0.1300\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 14.1246 - accuracy: 0.0918 - val_loss: 14.6030 - val_accuracy: 0.1300\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 14.5550 - accuracy: 0.0907 - val_loss: 14.7804 - val_accuracy: 0.1300\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 14.7454 - accuracy: 0.0893 - val_loss: 14.8271 - val_accuracy: 0.1300\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 14.6812 - accuracy: 0.0933 - val_loss: 14.8577 - val_accuracy: 0.1300\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb16e2bfba8>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "data_dim = 16\n",
    "timesteps = 8\n",
    "num_classes = 10\n",
    "\n",
    "# 期望输入数据的尺寸：(batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True, input_shape=(timesteps, data_dim)))# 返回维度为32的向量序列\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "# 生成虚拟数据\n",
    "x_train = np.random.random((1000, timesteps, data_dim))\n",
    "y_train = np.random.random((1000, num_classes))\n",
    "\n",
    "# 生成虚拟验证数据\n",
    "x_val = np.random.random((100, timesteps, data_dim))\n",
    "y_val = np.random.random((100, num_classes))\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=5, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras函数式API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 0s 841us/step - loss: 43.1719 - accuracy: 0.1138\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 0s 880us/step - loss: 183.6869 - accuracy: 0.0906\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 0s 851us/step - loss: 299.9474 - accuracy: 0.1032\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 0s 863us/step - loss: 443.2224 - accuracy: 0.1135\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 0s 887us/step - loss: 542.0868 - accuracy: 0.1172\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 562.3103 - accuracy: 0.0901\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 476.6397 - accuracy: 0.0899\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 0s 938us/step - loss: 348.5947 - accuracy: 0.0994\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 471.8204 - accuracy: 0.1117\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 571.7608 - accuracy: 0.0814\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb1519a25f8>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "\n",
    "# 全连接网络\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "# 这部分返回一个张量\n",
    "inputs = Input(shape=(784, ))\n",
    "\n",
    "# 层的实例是可调用的，它以张量为参数，并返回一个张量\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# 这部分创建了一个包含输入层和三个全连接层的模型\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#print(type(data), labels)\n",
    "data = np.random.random((1000, 784))\n",
    "labels = np.random.random((1000, 10))\n",
    "model.fit(data, labels, epochs=10, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./test.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Functional\", \"config\": {\"name\": \"model\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 784], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"input_1\"}, \"name\": \"input_1\", \"inbound_nodes\": []}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_14\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 64, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"name\": \"dense_14\", \"inbound_nodes\": [[[\"input_1\", 0, 0, {}]]]}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_15\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 64, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"name\": \"dense_15\", \"inbound_nodes\": [[[\"dense_14\", 0, 0, {}]]]}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_16\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 10, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"name\": \"dense_16\", \"inbound_nodes\": [[[\"dense_15\", 0, 0, {}]]]}], \"input_layers\": [[\"input_1\", 0, 0]], \"output_layers\": [[\"dense_16\", 0, 0]]}, \"keras_version\": \"2.4.0\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 784)]             0         \n_________________________________________________________________\ndense_14 (Dense)             (None, 64)                50240     \n_________________________________________________________________\ndense_15 (Dense)             (None, 64)                4160      \n_________________________________________________________________\ndense_16 (Dense)             (None, 10)                650       \n=================================================================\nTotal params: 55,050\nTrainable params: 55,050\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'weights' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-2899ff310f75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#返回模型中所有张量的列表，类型为Numpy数组\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#从numpy数组中为模型设置权重，列表中的数组必须与get_weights()返回的权重具有想通的尺寸。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#以JSON字符串的形式返回模型的表示。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'weights' is not defined"
     ]
    }
   ],
   "source": [
    "#模型的保存和加载\n",
    "model.save('./111.h5')\n",
    "from keras.models import load_model\n",
    "model = load_model('./111.h5')\n",
    "\n",
    "# keras模型的一些方法\n",
    "model.layers#包含模型网络层的展平列表\n",
    "model.inputs#模型输入张量的列表\n",
    "model.outputs#模型输出张量的列表\n",
    "model.summary()#打印模型概述信息\n",
    "model.get_config()#返回包含模型配置信息的字典。通过下面的代码，可以根据配置信息重新实例化模型\n",
    "config = model.get_config()\n",
    "model = Model.from_config(config)\n",
    "# 或者对于Sequential\n",
    "model = Sequential.from_config(config)\n",
    "\n",
    "model.get_weights()#返回模型中所有张量的列表，类型为Numpy数组\n",
    "model.set_weights(weights)#从numpy数组中为模型设置权重，列表中的数组必须与get_weights()返回的权重具有想通的尺寸。\n",
    "model.to_json()#以JSON字符串的形式返回模型的表示。\n",
    "\n",
    "#使用以下方式从JSON字符串重新实例化模型\n",
    "from keras.models import model_from_json\n",
    "\n",
    "m_json = model.to_json()\n",
    "model = model_from_json(m_json)\n",
    "\n",
    "model.to_yaml()#以YAML字符串形式返回模型的表示。注意，该表示不包括权重，只包括结构。\n",
    "\n",
    "#以下方式通过YAML重新实例化模型，使用重新初始化的权重\n",
    "from keras.models import model_from_yaml\n",
    "m_yaml = model.to_yaml()\n",
    "model = model_from_yaml(m_yaml)\n",
    "\n",
    "model.save_weights('filepath')#将模型权重存储为HDF5文件\n",
    "model.load_weights('filepath', by_name=False)#从HDF5文件（由save_weights创建）中加载权重。默认下，模型结构不变。如果想加载进不同结构的模型，可以使用参数by_name=True，加载同名层的权重。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多输入多输出模型\n",
    "函数式API使处理大量交织的数据流变得容易\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 标题输入：接受一个含有100个整数的序列，每个整数在1到10000之间\n",
    "# 注意我们可以通过传递一个“name”参数来命名任何层\n",
    "main_input = Input(shape=(100,), dtype='int32', name='main_input')\n",
    "\n",
    "# Embedding层将输入序列编码为一个稠密向量的序列，每个向量维度为512\n",
    "x = Embedding(output_dim=512, input_dim=10000, input_length=100)(main_input)\n",
    "\n",
    "# LSTM层把向量序列转换成单个向量，它包含整个序列的上下文信息\n",
    "lstm_out = LSTM(32)(x)\n",
    "\n",
    "# 在这里，我们插入辅助损失，使得即使在模型主损失很高的情况下，LSTM层和Embedding层都能被平稳地训练\n",
    "auxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(lstm_out)\n",
    "\n",
    "# 此时，我们将辅助输入数据与LSTM层的输出链接起来，输入到模型中：\n",
    "auxiliary_input = Input(shape=(5,), name='aux_input')\n",
    "x = keras.layers.concatenate([lstm_out, auxiliary_input])\n",
    "\n",
    "# 堆叠多个全连接网络层\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "# 最后添加主要的逻辑回归层\n",
    "main_output = Dense(1, activation='sigmoid', name='main_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#然后定义一个具有两个输入和两个输出的模型\n",
    "model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output, auxiliary_output])\n",
    "\n",
    "# 现在编译模型，给辅助损失分配0.2的权重，如果要为不同的输出指定不同的loss_weights或loss，可以使用列表或字典，\n",
    "# 这里我们给loss参数传递单个损失函数，将这个损失用于所有的输出\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', loss_weights=[1., 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([headline_data, additional_data], [labels, labels], epochs=50, batch_size=32)\n",
    "\n",
    "# 由于我们通过name参数为输入、输出层进行了命名，所以可通过一下方式进行训练\n",
    "model.compile(optimizer='rmsprop',\n",
    "                loss={'main_input': 'binary_crossentropy', 'aux_input': 'binary_crossentropy'},\n",
    "              loss_weights={'main_output': 1., 'aux_output': 0.2}\n",
    "             )\n",
    "\n",
    "model.fit({'main_input': headline_data, 'auxiliary_input': additional_data}, \n",
    "          {'main_output': labels, 'auxiliary_output': labels}, \n",
    "          epochs=50,\n",
    "          batch_size=32\n",
    "         )\n"
   ]
  },
  {
   "source": [
    "# 模型的一些常用的方法"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers # 包含模型网络层的展平列表\n",
    "model.inputs # 模型输入张量的列表\n",
    "model.outputs # 模型输出张量的列表\n",
    "model.summary() # 打印模型概述信息\n",
    "model.get_config() # 返回包含模型配置信息的字典"
   ]
  },
  {
   "source": [
    "# Keras网络层\n",
    "网络层（layer）有很多共同的函数"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = Dense(32)\n",
    "\n",
    "weights = layer.get_weights()  # 以含有Numpy矩阵的列表形式返回层的权重\n",
    "layer.set_weights(weights) # 从含有Numpy举证的列表中设置层的权重\n",
    "\n",
    "config = layer.get_config() # 返回包含层配置的字典\n",
    "reconstructed_layer = Dense.from_config(config)\n",
    "\n",
    "# 或者如下\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "config = layer.get_config()\n",
    "layer = layers.deserialize({'class_name': layer.__class__.__name__, 'config': config})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "source": [
    "# keras的循环层RNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a18b28fa8da3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgo_backwards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstateful\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munroll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "keras.layers.RNN(cell, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False)"
   ]
  },
  {
   "source": [
    "# LSTM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-30269aec1189>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tanh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurrent_activation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hard_sigmoid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glorot_uniform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurrent_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'orthogonal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zeros'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit_forget_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurrent_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurrent_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurrent_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimplementation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgo_backwards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstateful\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munroll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "keras.layers.LSTM(units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False)\n"
   ]
  },
  {
   "source": [
    "# Embedding层"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding\n",
    "import numpy as np\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(1000, 64, input_length=10))\n",
    "# 模型将输入一个大小为（batch，input_length）的整数矩阵\n",
    "# 输入中最大的整数（即此索引）不应该大于999（词汇表大小）\n",
    "# 现在model.output_shape == (None, 10, 64)，其中None是batch的维度，一个batch代表一个样本\n",
    "\n",
    "# 可以理解为1000个样本，每个样本是由32句话构成，每句话是10个词。\n",
    "input_array = np.random.randint(1000, size=(32,10))\n",
    "\n",
    "\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)\n",
    "# 输出的形状是（32，10，64）32句话构成一个样本，每句10个词，每个词变成了64维的向量\n",
    "assert output_array.shape == (32, 10, 64)"
   ]
  },
  {
   "source": [
    "# 融合层\n",
    "该部分内容讲述的都是两个张量之间的融合，一个实现融合的层\n",
    "## Add\n",
    "keras.layers.Add()\n",
    "\n",
    "计算输入张量列表的和\n",
    "\n",
    "它接受一个张量的列表，所有的张量必须有相同的输入尺寸，然后返回一个张量（和输入张量尺寸相同）。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  tensorflow import keras\n",
    "\n",
    "input1 = keras.layers.Input(shape=(16,))\n",
    "x1 = keras.layers.Dense(8, activation='relu')(input1)\n",
    "input2 = keras.layers.Input(shape=(32,))\n",
    "x2 = keras.layers.Dense(8, activation='relu')(input2)\n",
    "# 相当于 added = keras.layers.add([x1, x2])\n",
    "added = keras.layers.Add()([x1, x2])\n",
    "\n",
    "out = keras.layers.Dense(4)(added)\n",
    "model = keras.models.Model(inputs=[input1, input2], outputs=out)"
   ]
  },
  {
   "source": [
    "## Dot\n",
    "keras.layers.Dot(axes, normalize=False)\n",
    "\n",
    "计算两个张量之间样本的点积"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}